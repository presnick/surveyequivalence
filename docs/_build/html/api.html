
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>API &#8212; SurveyEquivalence 1.0 documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/alabaster.css" />
    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/sphinx_highlight.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="Tutorials" href="tutorials.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="api">
<h1>API<a class="headerlink" href="#api" title="Permalink to this heading">¶</a></h1>
<section id="equivalence-module">
<h2>Equivalence Module<a class="headerlink" href="#equivalence-module" title="Permalink to this heading">¶</a></h2>
<section id="analysispipeline">
<h3>AnalysisPipeline<a class="headerlink" href="#analysispipeline" title="Permalink to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="surveyequivalence.equivalence.AnalysisPipeline">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">surveyequivalence.equivalence.</span></span><span class="sig-name descname"><span class="pre">AnalysisPipeline</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">W</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sparse_experts</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">expert_cols</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">amateur_cols</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">classifier_predictions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">combiner</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#surveyequivalence.combiners.Combiner" title="surveyequivalence.combiners.Combiner"><span class="pre">Combiner</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scorer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#surveyequivalence.scoring_functions.Scorer" title="surveyequivalence.scoring_functions.Scorer"><span class="pre">Scorer</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">allowable_labels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_k</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_bootstrap_item_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_rater_subsets</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">200</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_K</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ratersets_memo</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">predictions_memo</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">item_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">performance_ratio_k</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">anonymous_raters</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbosity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">run_on_creation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">procs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">7</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.equivalence.AnalysisPipeline" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>The main class for running an analysis</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>W</strong> (<em>pd.DataFrame</em>) -- The ratings dataframe with one column for each rater, one row for each item</p></li>
<li><p><strong>sparse_experts</strong> (<em>bool</em>) -- True (default) if some raters may not have rated all items</p></li>
<li><p><strong>expert_cols</strong> (<em>Sequence</em><em>[</em><em>str</em><em>] </em><em>=</em><em> [</em><em>]</em>) -- A list of column names, one for each potential &quot;reference rater&quot; whose the classifier is trying to         predict. These are also the columns used for computing the power curve for survey equivalence</p></li>
<li><p><strong>amateur_cols</strong> (<em>Sequence</em><em>[</em><em>str</em><em>] </em><em>=</em><em> [</em><em>]</em>) -- A list of column names, one for each potential &quot;other rater&quot;. Their ratings are not used for evaluating         the classifier, but a separate power curve may be computed for them, using surveys of k of them         to predict a reference rater's label. Survey equivalences can also be calculated between j &quot;other raters&quot;         and k reference raters.</p></li>
<li><p><strong>classifier_predictions</strong> (<em>pd.DataFrame = None</em>) -- A dataframe with one column for each classifier for which we want to compute survey equivalences.         One row for each item; row indexes should be the same as for W</p></li>
<li><p><strong>combiner</strong> (<em>Combiner = None</em>) -- A combiner that is used to make a prediction about the next label for an item,         given labels from some other raters.</p></li>
<li><p><strong>scorer</strong> (<em>Scorer = None</em>) -- A scorer that takes a vector of predictions and a vector of realized reference rater labels and         yields a numeric score.</p></li>
<li><p><strong>allowable_labels</strong> (<em>Sequence</em><em>[</em><em>str</em><em>] </em><em>= None</em>) -- A list of the potential label strings that a rater is permitted to assign to an item</p></li>
<li><p><strong>min_k=0</strong> -- When computing power curves, the smallest survey size to include</p></li>
<li><p><strong>num_bootstrap_item_samples=100</strong> -- When computing error bars, how many bootstrap samples of items to create</p></li>
<li><p><strong>max_rater_subsets=200</strong> -- When computing power curves, we compute the average score over predictions made from many subsets         of reference raters of size k. When k is small, we choose all subsets of size k. For larger k,         we take a sample from the powerset. This parameters determines how many subsets to select.</p></li>
<li><p><strong>max_K=10</strong> -- When computing computing curves, the largest survey size to include. Cannot be larger than         the number of reference raters in W, minus one.</p></li>
<li><p><strong>ratersets_memo=None</strong> -- While running, a dictionary is create to memoize certain computations, for efficiency. A value         be passed in in order to reuse the memoized computations from a previous run.</p></li>
<li><p><strong>predictions_memo=None</strong> -- While running, a dictionary is create to memoize certain computations, for efficiency. A value         be passed in in order to reuse the memoized computations from a previous run.</p></li>
<li><p><strong>item_samples=None</strong> -- If specified, the set of bootstrap item samples to use for computing error bars.         If not specified, a new set of bootstrap item samples will be created.</p></li>
<li><p><strong>performance_ratio_k=None</strong> -- Parameter k for the performance_ratio: classifier's information gain over k raters' information gain</p></li>
<li><p><strong>anonymous_raters=False</strong> -- If False, then each column in W represents an individual rater. If True, then raters are anonymous and
not all labels in a column came from the same rater.</p></li>
<li><p><strong>verbosity=1</strong> -- Controls how much information is printed to the console during execution. Set a higher number         to help with debugging.</p></li>
<li><p><strong>True</strong> (<em>run_on_creation =</em>) -- Whether to actually run the analysis pipeline</p></li>
<li><p><strong>1</strong> (<em>procs=pathos.helpers.cpu_count</em><em>(</em><em>) </em><em>-</em>) -- How many processors are available for parallel execution</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="surveyequivalence.equivalence.AnalysisPipeline.output_csv">
<span class="sig-name descname"><span class="pre">output_csv</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fname</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.equivalence.AnalysisPipeline.output_csv" title="Permalink to this definition">¶</a></dt>
<dd><p>output the dataframe and the expert predictions</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="surveyequivalence.equivalence.AnalysisPipeline.path_for_saving">
<span class="sig-name descname"><span class="pre">path_for_saving</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dirname_base</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'analysis_pipeline'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include_timestamp</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.equivalence.AnalysisPipeline.path_for_saving" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dirname_base</strong> -- A name that describes the analysis; / will be treated as a subdirectory</p></li>
<li><p><strong>include_timestamp</strong> -- Whether to make a folder indicating the timestamp at which the run was done.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><em>A path of the form {self.run_timestamp}/{dirname_base}</em></p></li>
<li><p><em>If the path does not exist yet, it is created.</em></p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="surveyequivalence.equivalence.AnalysisPipeline.run">
<span class="sig-name descname"><span class="pre">run</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.equivalence.AnalysisPipeline.run" title="Permalink to this definition">¶</a></dt>
<dd><p>Create the power curve(s); normally invoked during __init__ but can be called separately.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="surveyequivalence.equivalence.AnalysisPipeline.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">msg</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_results</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.equivalence.AnalysisPipeline.save" title="Permalink to this definition">¶</a></dt>
<dd><p>Save instance and results to files</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dirname_base=&quot;analysis_pipeline&quot;</strong> -- A subdirectory name in which to store saved results</p></li>
<li><p><strong>msg</strong> -- A text string to write in a README file that is generated</p></li>
<li><p><strong>save_results=True</strong> -- If True, generates a <cite>results_summary.txt</cite> file with power curve and survey equivalence summary stats</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="surveyequivalence.equivalence.load_saved_pipeline">
<span class="sig-prename descclassname"><span class="pre">surveyequivalence.equivalence.</span></span><span class="sig-name descname"><span class="pre">load_saved_pipeline</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.equivalence.load_saved_pipeline" title="Permalink to this definition">¶</a></dt>
<dd><p>Loads dataset, predictions, classifiers scores, and power curve(s) previously saved using     <a class="reference internal" href="#surveyequivalence.equivalence.AnalysisPipeline.save" title="surveyequivalence.equivalence.AnalysisPipeline.save"><code class="xref py py-meth docutils literal notranslate"><span class="pre">surveyequivalence.equivalence.AnalysisPipeline.save()</span></code></a></p>
</dd></dl>

</section>
<section id="plot">
<h3>Plot<a class="headerlink" href="#plot" title="Permalink to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="surveyequivalence.equivalence.Plot">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">surveyequivalence.equivalence.</span></span><span class="sig-name descname"><span class="pre">Plot</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ax</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">expert_power_curve</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">amateur_power_curve</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">classifier_scores</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">color_map</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{'amateur_power_curve':</span> <span class="pre">'blue',</span> <span class="pre">'classifier':</span> <span class="pre">'green',</span> <span class="pre">'expert_power_curve':</span> <span class="pre">'black'}</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_axis_label</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'Agreement</span> <span class="pre">with</span> <span class="pre">reference</span> <span class="pre">rater'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">center_on</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'powercurve'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">legend_label</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'Expert</span> <span class="pre">raters'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">amateur_legend_label</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'Lay</span> <span class="pre">raters'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbosity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">performance_ratio_k</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">generate_pgf</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.equivalence.Plot" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Generates visual display of power curve(s) and classifier scores, as matplotlib objects and as pgf for embedding in latex.     First run AnalysisPipeline to generate the PowerCurve and ClassifierResults objects to pass in to constructor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ax</strong> (<em>matplotlib.axes.Axes</em>) -- </p></li>
<li><p><strong>expert_power_curve</strong> (<a class="reference internal" href="#surveyequivalence.equivalence.PowerCurve" title="surveyequivalence.equivalence.PowerCurve"><em>PowerCurve</em></a>) -- a PowerCurve with scores for combinations of k reference raters in predicting a held-out reference rater</p></li>
<li><p><strong>amateur_power_curve=None</strong> (<a class="reference internal" href="#surveyequivalence.equivalence.PowerCurve" title="surveyequivalence.equivalence.PowerCurve"><em>PowerCurve</em></a>) -- a PowerCurve with scores for combinations of k other raters in predicting a held-out reference rater</p></li>
<li><p><strong>classifier_scores=None</strong> (<a class="reference internal" href="#surveyequivalence.equivalence.ClassifierResults" title="surveyequivalence.equivalence.ClassifierResults"><em>ClassifierResults</em></a>) -- </p></li>
<li><p><strong>color_map={'expert_power_curve'</strong> (<em>'black'</em><em>, </em><em>'amateur_power_curve': 'blue'</em><em>, </em><em>'classifier': 'green'}</em>) -- a dictionary specifying colors to use for the different elements of the graph to be pltoted</p></li>
<li><p><strong>rater'</strong> (<em>y_axis_label='Agreement with reference</em>) -- </p></li>
<li><p><strong>center_on=None</strong> (<em>float</em>) -- If a value is provided, it will be subtracted from all scores for classifiers and power curve values</p></li>
<li><p><strong>y_range=None</strong> -- If specified, a tuple of two values, the min and max y-values for the graph</p></li>
<li><p><strong>name='powercurve'</strong> -- A name for the plot</p></li>
<li><p><strong>raters'</strong> (<em>legend_label='Expert</em>) -- Legend label for the power curve for reference raters</p></li>
<li><p><strong>raters&quot;</strong> (<em>amateur_legend_label=&quot;Lay</em>) -- Legend label for the power curve for other raters</p></li>
<li><p><strong>verbosity=1</strong> -- Controls how much information is printed to the console during execution. Set a higher number         to help with debugging.</p></li>
<li><p><strong>performance_ratio_k=None</strong> -- Parameter k for the performance_ratio: classifier's information gain over k raters' information gain</p></li>
<li><p><strong>generate_pgf=False</strong> -- If True, also populate data to enable create of pgf format, suitable for inclusion in latex         after calling <cite>.plot()</cite>, run         <cite>self.template.substitute(**self.template_dict)</cite></p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="surveyequivalence.equivalence.Plot.plot">
<span class="sig-name descname"><span class="pre">plot</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">include_expert_points</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'all'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">connect_expert_points</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include_classifiers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include_classifier_equivalences</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include_classifier_amateur_equivalences</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include_performance_ratio</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">other_rater_equivalences_to_include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include_droplines</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include_amateur_curve</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include_classifier_cis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include_seq_cis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x_ticks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">legend_loc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.equivalence.Plot.plot" title="Permalink to this definition">¶</a></dt>
<dd><p>The method that fills in the contents of the matplotlib Axes object</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include_expert_points='all'</strong> -- all means to plot all reference rater survey sizes on the x-axis of the power curve
Or include a list of numbers indicating which survey sizes to include</p></li>
<li><p><strong>connect_expert_points=True</strong> -- Whether to draw straight lines connecting the dots for survey power for surveys of successive sizes</p></li>
<li><p><strong>include_classifiers=True</strong> -- Whether to include horizontal lines showing the classifier score(s)</p></li>
<li><p><strong>include_classifier_equivalences=True</strong> -- Whether to include calculation of the equivalent number of reference raters for each classifier,             based on the intersection point of the classifier line and the reference raters' power curve</p></li>
<li><p><strong>include_classifier_amateur_equivalences=False</strong> -- Whether to include calculation of the equivalent number of other raters for each classifier,             based on the intersection point of the classifier line and the other raters' power curve</p></li>
<li><p><strong>include_performance_ratio=True</strong> -- Whether to include performance_ratio</p></li>
<li><p><strong>other_rater_equivalences_to_include=</strong><strong>[</strong><strong>]</strong> -- A list of survey sizes for non-reference raters.             For each one, compute the equivalent number of reference raters yielding the same score.</p></li>
<li><p><strong>include_droplines=True</strong> -- Whether to include vertical lines from the intersection points (survey equivalences) to the x-axis</p></li>
<li><p><strong>include_amateur_curve=True</strong> -- Whether to include a power curve for the other, non-reference raters</p></li>
<li><p><strong>include_classifier_cis=True</strong> -- Whether to include error bars around the classifier horizontal lines</p></li>
<li><p><strong>include_seq_cis=True</strong> -- Whether to include error bars around the survey equivalence values</p></li>
<li><p><strong>x_ticks=None</strong> -- If provided, a  list of x values for which tick marks should be shown.             If None, then it will be automatically calculated.</p></li>
<li><p><strong>legend_loc=None</strong> -- String indicating where to place the legend (uses default if None).             Options as documented for <a class="reference external" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.legend.html">matplotlib.axes.Axes.legend</a>.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="surveyequivalence.equivalence.Plot.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path:</span> <span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fig:</span> <span class="pre">&lt;module</span> <span class="pre">'matplotlib.figure'</span> <span class="pre">from</span> <span class="pre">'C:\\Users\\tweni\\PycharmProjects\\surveyequivalence\\temp1\\lib\\site-packages\\matplotlib\\figure.py'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">plotname='plot'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.equivalence.Plot.save" title="Permalink to this definition">¶</a></dt>
<dd><p>Wrapper for the matplotlib save_plot function. Saves all data to the ./plots directory as png and tex files.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fig</strong> (<em>matplotlib figure object to be saved</em>) -- </p></li>
<li><p><strong>name</strong> (<em>Name for the file</em>) -- </p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="equivalences">
<h3>Equivalences<a class="headerlink" href="#equivalences" title="Permalink to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="surveyequivalence.equivalence.Equivalences">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">surveyequivalence.equivalence.</span></span><span class="sig-name descname"><span class="pre">Equivalences</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">df</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.equivalence.Equivalences" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Contains a dataframe with one row for each bootstrap sample of items and one column for each classifier.     Cell contains the survey equivalence value (equivalent number of reference raters whose combined ratings     yields the same score as the classifier).</p>
<dl class="py property">
<dt class="sig sig-object py" id="surveyequivalence.equivalence.Equivalences.lower_bounds">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">lower_bounds</span></span><a class="headerlink" href="#surveyequivalence.equivalence.Equivalences.lower_bounds" title="Permalink to this definition">¶</a></dt>
<dd><p>rtype: A pandas Series with a lower bound on the survey equivalence for each classifier.         Compute based on interval covering 95% of the bootstrap samples of items, if there are more than 200 of them.         Otherwise compute based on two standard deviations of the scores on bootstrap samples.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="surveyequivalence.equivalence.Equivalences.upper_bounds">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">upper_bounds</span></span><a class="headerlink" href="#surveyequivalence.equivalence.Equivalences.upper_bounds" title="Permalink to this definition">¶</a></dt>
<dd><p>rtype: A pandas Series with an upper bound on the survey equivalence for each classifier.         Compute based on interval covering 95% of the bootstrap samples of items, if there are more than 200 of them.         Otherwise compute based on two standard deviations of the scores on bootstrap samples.</p>
</dd></dl>

</dd></dl>

</section>
<section id="classifierresults">
<h3>ClassifierResults<a class="headerlink" href="#classifierresults" title="Permalink to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="surveyequivalence.equivalence.ClassifierResults">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">surveyequivalence.equivalence.</span></span><span class="sig-name descname"><span class="pre">ClassifierResults</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">runs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">df</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.equivalence.ClassifierResults" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<dl class="py property">
<dt class="sig sig-object py" id="surveyequivalence.equivalence.ClassifierResults.lower_bounds">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">lower_bounds</span></span><a class="headerlink" href="#surveyequivalence.equivalence.ClassifierResults.lower_bounds" title="Permalink to this definition">¶</a></dt>
<dd><p>rtype: A pandas Series with a lower bound on the survey equivalence for each classifier.         Compute based on interval covering 95% of the bootstrap samples of items, if there are more than 200 of them.         Otherwise compute based on two standard deviations of the scores on bootstrap samples.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="surveyequivalence.equivalence.ClassifierResults.upper_bounds">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">upper_bounds</span></span><a class="headerlink" href="#surveyequivalence.equivalence.ClassifierResults.upper_bounds" title="Permalink to this definition">¶</a></dt>
<dd><p>rtype: A pandas Series with an upper bound on the survey equivalence for each classifier.         Compute based on interval covering 95% of the bootstrap samples of items, if there are more than 200 of them.         Otherwise compute based on two standard deviations of the scores on bootstrap samples.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="surveyequivalence.equivalence.ClassifierResults.values">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">values</span></span><a class="headerlink" href="#surveyequivalence.equivalence.ClassifierResults.values" title="Permalink to this definition">¶</a></dt>
<dd><p>rtype: Series of classifier scores for the first row, the actual item set, omitting results for all bootstrap item sets.</p>
</dd></dl>

</dd></dl>

</section>
<section id="powercurve">
<h3>PowerCurve<a class="headerlink" href="#powercurve" title="Permalink to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="surveyequivalence.equivalence.PowerCurve">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">surveyequivalence.equivalence.</span></span><span class="sig-name descname"><span class="pre">PowerCurve</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">runs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">df</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.equivalence.PowerCurve" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#surveyequivalence.equivalence.ClassifierResults" title="surveyequivalence.equivalence.ClassifierResults"><code class="xref py py-class docutils literal notranslate"><span class="pre">ClassifierResults</span></code></a></p>
<p>A special case of ClassifierResults where there is one column for each integer value k,     representing the mean score, over many samples of k raters, of the predictions generated by     combining ratings from k raters, scored against a reference rater.</p>
<dl class="py method">
<dt class="sig sig-object py" id="surveyequivalence.equivalence.PowerCurve.compute_equivalence_at_actuals">
<span class="sig-name descname"><span class="pre">compute_equivalence_at_actuals</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">classifier_score</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.equivalence.PowerCurve.compute_equivalence_at_actuals" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the equivalence of the score of the classifier on the actual item sample         based on the survey power curve computed for the actual item sample</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="surveyequivalence.equivalence.PowerCurve.compute_equivalence_at_mean">
<span class="sig-name descname"><span class="pre">compute_equivalence_at_mean</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">classifier_score</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.equivalence.PowerCurve.compute_equivalence_at_mean" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the equivalence of the mean score of the classifier across the bootstrap item samples         based on the mean survey power curve computed across the bootstrap item samples</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="surveyequivalence.equivalence.PowerCurve.compute_equivalences">
<span class="sig-name descname"><span class="pre">compute_equivalences</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">other</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">columns</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.equivalence.PowerCurve.compute_equivalences" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>self</strong> -- </p></li>
<li><p><strong>other</strong> -- The classifier scores that are compared against this PowerCurve to find equivalences
may either be an instance of ClassifierResults or a PowerCurve. Must have same row             indexes as self, one for each item sample</p></li>
<li><p><strong>columns</strong> -- a subset of the column names from other.df; if not specified, use all of them</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>a df with one row for each bootstrap run, and columns as specified by the columns parameter             Each cell is a float, the survey equivalence value for that column from other.             That is, the x s.t. expected score with x raters from self == classifier_score from other.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="surveyequivalence.equivalence.PowerCurve.reliability_of_beating_classifier">
<span class="sig-name descname"><span class="pre">reliability_of_beating_classifier</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">other</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">other_col</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.equivalence.PowerCurve.reliability_of_beating_classifier" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>other</strong> -- the other ClassifierResults or PowerCurve</p></li>
<li><p><strong>self_col</strong> -- the survey size (column) for self</p></li>
<li><p><strong>other_col</strong> -- the survey size (column) for other to compare, with matching bootstrap samples as rows</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>fraction of bootstrap runs where self power higher than other power</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="surveyequivalence.equivalence.PowerCurve.reliability_of_difference">
<span class="sig-name descname"><span class="pre">reliability_of_difference</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">other</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.equivalence.PowerCurve.reliability_of_difference" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>other</strong> -- another PowerCurve</p></li>
<li><p><strong>k</strong> -- survey size</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>fraction of bootstrap runs where power&#64;k higher for self than other power curve</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
</section>
<section id="module-surveyequivalence.combiners">
<span id="combiners"></span><h2>Combiners<a class="headerlink" href="#module-surveyequivalence.combiners" title="Permalink to this heading">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="surveyequivalence.combiners.AnonymousBayesianCombiner">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">surveyequivalence.combiners.</span></span><span class="sig-name descname"><span class="pre">AnonymousBayesianCombiner</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.combiners.AnonymousBayesianCombiner" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#surveyequivalence.combiners.Combiner" title="surveyequivalence.combiners.Combiner"><code class="xref py py-class docutils literal notranslate"><span class="pre">Combiner</span></code></a></p>
<p>Anonymous Bayesian Combiner Class</p>
<dl class="py method">
<dt class="sig sig-object py" id="surveyequivalence.combiners.AnonymousBayesianCombiner.combine">
<span class="sig-name descname"><span class="pre">combine</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">allowable_labels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">W</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">matrix</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">item_id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">to_predict_for</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#surveyequivalence.combiners.DiscreteDistributionPrediction" title="surveyequivalence.combiners.DiscreteDistributionPrediction"><span class="pre">DiscreteDistributionPrediction</span></a></span></span><a class="headerlink" href="#surveyequivalence.combiners.AnonymousBayesianCombiner.combine" title="Permalink to this definition">¶</a></dt>
<dd><p>Algorithm 6
Compute the anonymous bayesian combiner. Combines rater labels like frequency_combiner, but this uses the
information from the item/rating dataset W.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>allowable_labels</strong> (<em>the set</em><em> of </em><em>labels/ratings allowed</em>) -- </p></li>
<li><p><strong>labels</strong> (<em>the k ratings</em>) -- </p></li>
<li><p><strong>W</strong> (<em>item and rating dataset</em>) -- </p></li>
<li><p><strong>item_id</strong> (<em>item index in W we are predicting for</em>) -- </p></li>
<li><p><strong>to_predict_for</strong> (<em>not used currently</em>) -- </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Prediction based on anonymous bayesian combiner</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="surveyequivalence.combiners.AnonymousBayesianCombiner.labelSeqProb">
<span class="sig-name descname"><span class="pre">labelSeqProb</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">allowable_labels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">W</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">matrix</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">item_id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">to_predict_for</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">float</span></span></span><a class="headerlink" href="#surveyequivalence.combiners.AnonymousBayesianCombiner.labelSeqProb" title="Permalink to this definition">¶</a></dt>
<dd><p>Algorithm 5: LabelSeqProb</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="surveyequivalence.combiners.AnonymousBayesianCombiner.probabilityOneItem">
<span class="sig-name descname"><span class="pre">probabilityOneItem</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y:</span> <span class="pre">~numpy.array</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">item:</span> <span class="pre">~numpy.array</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">allowable_labels:</span> <span class="pre">~typing.Sequence[str])</span> <span class="pre">-&gt;</span> <span class="pre">(&lt;class</span> <span class="pre">'float'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">&lt;class</span> <span class="pre">'int'&gt;</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.combiners.AnonymousBayesianCombiner.probabilityOneItem" title="Permalink to this definition">¶</a></dt>
<dd><p>ProbabilityOneItem function in Algorithm 5. Computes the contribution of a single item to the combiner</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y</strong> (<em>vector</em><em> of </em><em>observed label counts that we are trying to find joint distribution for</em>) -- </p></li>
<li><p><strong>item</strong> (<em>The item's labels</em>) -- </p></li>
<li><p><strong>allowable_labels</strong> (<em>The set</em><em> of </em><em>labels that can be entered by the raters.</em>) -- </p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><em>The contribution of this item.</em></p></li>
<li><p><em>A 0,1 flag for whether this item had enough labels to be used in this way</em></p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="surveyequivalence.combiners.AnonymousBayesianCombiner.sumOfProbabilities">
<span class="sig-name descname"><span class="pre">sumOfProbabilities</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y:</span> <span class="pre">~numpy.array</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">W:</span> <span class="pre">~numpy.matrix</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">allowable_labels:</span> <span class="pre">~typing.Sequence[str])</span> <span class="pre">-&gt;</span> <span class="pre">(&lt;class</span> <span class="pre">'float'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">&lt;class</span> <span class="pre">'int'&gt;</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.combiners.AnonymousBayesianCombiner.sumOfProbabilities" title="Permalink to this definition">¶</a></dt>
<dd><p>SumOfProbabilities procedure in Algorithm 5 in the paper</p>
<p>Compute the joint distribution over k anonymous ratings</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y</strong> (<em>vector</em><em> of </em><em>observed label counts that we are trying to find joint distribution for</em>) -- </p></li>
<li><p><strong>W</strong> (<em>item and rating dataset</em>) -- </p></li>
<li><p><strong>allowable_labels</strong> (<em>The set</em><em> of </em><em>labels that can be entered by the raters.</em>) -- </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>joint distribution, and num_items</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="surveyequivalence.combiners.Combiner">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">surveyequivalence.combiners.</span></span><span class="sig-name descname"><span class="pre">Combiner</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">allowable_labels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">W</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbosity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.combiners.Combiner" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">ABC</span></code></p>
<p>Abstract class defining a combiner.</p>
<p>A combiner selects a single label from a bag/multiset of labels (and possibly other information) according to some
function. For example, the PluralityCombiner accepts a bag of labels and returns the label that is most frequent.</p>
<dl class="py method">
<dt class="sig sig-object py" id="surveyequivalence.combiners.Combiner.combine">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">combine</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">allowable_labels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">W</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">matrix</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">item_id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">to_predict_for</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#surveyequivalence.combiners.DiscreteDistributionPrediction" title="surveyequivalence.combiners.DiscreteDistributionPrediction"><span class="pre">DiscreteDistributionPrediction</span></a></span></span><a class="headerlink" href="#surveyequivalence.combiners.Combiner.combine" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="surveyequivalence.combiners.DiscreteDistributionPrediction">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">surveyequivalence.combiners.</span></span><span class="sig-name descname"><span class="pre">DiscreteDistributionPrediction</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">label_names</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">probabilities</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">extreme_cutoff</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.02</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.combiners.DiscreteDistributionPrediction" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#surveyequivalence.combiners.Prediction" title="surveyequivalence.combiners.Prediction"><code class="xref py py-class docutils literal notranslate"><span class="pre">Prediction</span></code></a></p>
<p>A discrete distribution prediction where labels are associated with probabilities. Value takes the label with the
highest probability.</p>
<dl class="py method">
<dt class="sig sig-object py" id="surveyequivalence.combiners.DiscreteDistributionPrediction.draw_discrete_label">
<span class="sig-name descname"><span class="pre">draw_discrete_label</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.combiners.DiscreteDistributionPrediction.draw_discrete_label" title="Permalink to this definition">¶</a></dt>
<dd><p>Return one of the labels, drawn according to the distribution</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>A label</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="surveyequivalence.combiners.DiscreteDistributionPrediction.label_probability">
<span class="sig-name descname"><span class="pre">label_probability</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">label</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.combiners.DiscreteDistributionPrediction.label_probability" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the probability associated with an input label</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>label</strong> (<em>label to query</em>) -- </p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Probability assicated with label.</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="surveyequivalence.combiners.DiscreteDistributionPrediction.value">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">value</span></span><a class="headerlink" href="#surveyequivalence.combiners.DiscreteDistributionPrediction.value" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the single label that has the highest predicted probability.
Break ties by taking the first one</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">DiscreteDistributionPrediction</span><span class="p">([</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;c&#39;</span><span class="p">],</span> <span class="p">[</span><span class="mf">.3</span><span class="p">,</span> <span class="mf">.4</span><span class="p">,</span> <span class="mf">.3</span><span class="p">])</span><span class="o">.</span><span class="n">value</span>
<span class="go">&#39;b&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">DiscreteDistributionPrediction</span><span class="p">([</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;c&#39;</span><span class="p">],</span> <span class="p">[</span><span class="mf">.4</span><span class="p">,</span> <span class="mf">.4</span><span class="p">,</span> <span class="mf">.2</span><span class="p">])</span><span class="o">.</span><span class="n">value</span>
<span class="go">&#39;a&#39;</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>label with highest probability</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="surveyequivalence.combiners.DiscreteDistributionPrediction.value_prob">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">value_prob</span></span><a class="headerlink" href="#surveyequivalence.combiners.DiscreteDistributionPrediction.value_prob" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the probability of the majority class</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">DiscreteDistributionPrediction</span><span class="p">([</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;c&#39;</span><span class="p">],</span> <span class="p">[</span><span class="mf">.3</span><span class="p">,</span> <span class="mf">.4</span><span class="p">,</span> <span class="mf">.3</span><span class="p">])</span><span class="o">.</span><span class="n">value</span>
<span class="go">.4</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">DiscreteDistributionPrediction</span><span class="p">([</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;c&#39;</span><span class="p">],</span> <span class="p">[</span><span class="mf">.4</span><span class="p">,</span> <span class="mf">.4</span><span class="p">,</span> <span class="mf">.2</span><span class="p">])</span><span class="o">.</span><span class="n">value</span>
<span class="go">.4</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>highest probability</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="surveyequivalence.combiners.DiscretePrediction">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">surveyequivalence.combiners.</span></span><span class="sig-name descname"><span class="pre">DiscretePrediction</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">label</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.combiners.DiscretePrediction" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#surveyequivalence.combiners.Prediction" title="surveyequivalence.combiners.Prediction"><code class="xref py py-class docutils literal notranslate"><span class="pre">Prediction</span></code></a></p>
<p>A discrete prediction. value is defined as a label</p>
<dl class="py property">
<dt class="sig sig-object py" id="surveyequivalence.combiners.DiscretePrediction.value">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">value</span></span><a class="headerlink" href="#surveyequivalence.combiners.DiscretePrediction.value" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="surveyequivalence.combiners.FrequencyCombiner">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">surveyequivalence.combiners.</span></span><span class="sig-name descname"><span class="pre">FrequencyCombiner</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">allowable_labels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">W</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbosity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.combiners.FrequencyCombiner" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#surveyequivalence.combiners.Combiner" title="surveyequivalence.combiners.Combiner"><code class="xref py py-class docutils literal notranslate"><span class="pre">Combiner</span></code></a></p>
<p>Returns a vector of frequencies for each label</p>
<dl class="py method">
<dt class="sig sig-object py" id="surveyequivalence.combiners.FrequencyCombiner.combine">
<span class="sig-name descname"><span class="pre">combine</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">allowable_labels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">W</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">matrix</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">item_id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">to_predict_for</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#surveyequivalence.combiners.DiscreteDistributionPrediction" title="surveyequivalence.combiners.DiscreteDistributionPrediction"><span class="pre">DiscreteDistributionPrediction</span></a></span></span><a class="headerlink" href="#surveyequivalence.combiners.FrequencyCombiner.combine" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the frequency vector for labels</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">FrequencyCombiner</span><span class="p">()</span><span class="o">.</span><span class="n">combine</span><span class="p">([</span><span class="s1">&#39;pos&#39;</span><span class="p">,</span> <span class="s1">&#39;neg&#39;</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([(</span><span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;pos&#39;</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;neg&#39;</span><span class="p">),</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="s1">&#39;neg&#39;</span><span class="p">)]),</span> <span class="p">)</span><span class="o">.</span><span class="n">probabilities</span>
<span class="go">[0.3333333333333333, 0.6666666666666666]</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">FrequencyCombiner</span><span class="p">()</span><span class="o">.</span><span class="n">combine</span><span class="p">([</span><span class="s1">&#39;pos&#39;</span><span class="p">,</span> <span class="s1">&#39;neg&#39;</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([(</span><span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;neg&#39;</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;neg&#39;</span><span class="p">),</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="s1">&#39;neg&#39;</span><span class="p">)]))</span><span class="o">.</span><span class="n">probabilities</span>
<span class="go">[0.0, 1.0]</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>allowable_labels</strong> (<em>not used in this combiner</em>) -- </p></li>
<li><p><strong>labels</strong> (<em>nnumeric values from particular rater ids; rater ids are ignored</em>) -- </p></li>
<li><p><strong>W</strong> (<em>not used in this combiner</em>) -- </p></li>
<li><p><strong>item_id</strong> (<em>not used in this combiner</em>) -- </p></li>
<li><p><strong>to_predict_for</strong> (<em>not used in this combiner</em>) -- </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Frequency vector of labels</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="surveyequivalence.combiners.MeanCombiner">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">surveyequivalence.combiners.</span></span><span class="sig-name descname"><span class="pre">MeanCombiner</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">allowable_labels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">W</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbosity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.combiners.MeanCombiner" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#surveyequivalence.combiners.Combiner" title="surveyequivalence.combiners.Combiner"><code class="xref py py-class docutils literal notranslate"><span class="pre">Combiner</span></code></a></p>
<p>Combiner that returns the mean of all the labels.</p>
<dl class="py method">
<dt class="sig sig-object py" id="surveyequivalence.combiners.MeanCombiner.combine">
<span class="sig-name descname"><span class="pre">combine</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">allowable_labels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">W</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">matrix</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">item_id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">to_predict_for</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#surveyequivalence.combiners.NumericPrediction" title="surveyequivalence.combiners.NumericPrediction"><span class="pre">NumericPrediction</span></a></span></span><a class="headerlink" href="#surveyequivalence.combiners.MeanCombiner.combine" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the single label that is most frequent</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>allowable_labels</strong> (<em>not used in this combiner</em>) -- </p></li>
<li><p><strong>labels</strong> (<em>nnumeric values from particular rater ids; rater ids are ignored</em>) -- </p></li>
<li><p><strong>W</strong> (<em>not used in this combiner</em>) -- </p></li>
<li><p><strong>item_id</strong> (<em>not used in this combiner</em>) -- </p></li>
<li><p><strong>to_predict_for</strong> (<em>not used in this combiner</em>) -- </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>The mean of the labels</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="surveyequivalence.combiners.NumericPrediction">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">surveyequivalence.combiners.</span></span><span class="sig-name descname"><span class="pre">NumericPrediction</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.combiners.NumericPrediction" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#surveyequivalence.combiners.Prediction" title="surveyequivalence.combiners.Prediction"><code class="xref py py-class docutils literal notranslate"><span class="pre">Prediction</span></code></a></p>
<p>A numeric prediction. value is defined as a number</p>
<dl class="py property">
<dt class="sig sig-object py" id="surveyequivalence.combiners.NumericPrediction.value">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">value</span></span><a class="headerlink" href="#surveyequivalence.combiners.NumericPrediction.value" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="surveyequivalence.combiners.PluralityVote">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">surveyequivalence.combiners.</span></span><span class="sig-name descname"><span class="pre">PluralityVote</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">allowable_labels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">W</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbosity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.combiners.PluralityVote" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#surveyequivalence.combiners.Combiner" title="surveyequivalence.combiners.Combiner"><code class="xref py py-class docutils literal notranslate"><span class="pre">Combiner</span></code></a></p>
<p>Combiner that returns the single label that is most frequent</p>
<dl class="py method">
<dt class="sig sig-object py" id="surveyequivalence.combiners.PluralityVote.combine">
<span class="sig-name descname"><span class="pre">combine</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">allowable_labels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">W</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">matrix</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">item_id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">to_predict_for</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#surveyequivalence.combiners.NumericPrediction" title="surveyequivalence.combiners.NumericPrediction"><span class="pre">NumericPrediction</span></a></span></span><a class="headerlink" href="#surveyequivalence.combiners.PluralityVote.combine" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the single label that is most frequent</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>allowable_labels</strong> (<em>not used in this combiner</em>) -- </p></li>
<li><p><strong>labels</strong> (<em>numeric values from particular rater ids; rater ids are ignored</em>) -- </p></li>
<li><p><strong>W</strong> (<em>not used in this combiner</em>) -- </p></li>
<li><p><strong>item_id</strong> (<em>not used in this combiner</em>) -- </p></li>
<li><p><strong>to_predict_for</strong> (<em>not used in this combiner</em>) -- </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>The most common label</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="surveyequivalence.combiners.Prediction">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">surveyequivalence.combiners.</span></span><span class="sig-name descname"><span class="pre">Prediction</span></span><a class="headerlink" href="#surveyequivalence.combiners.Prediction" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">ABC</span></code></p>
<p>Abstract class that defines a value for many types of Predictions</p>
<dl class="py property">
<dt class="sig sig-object py" id="surveyequivalence.combiners.Prediction.value">
<em class="property"><span class="pre">abstract</span><span class="w"> </span><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">value</span></span><a class="headerlink" href="#surveyequivalence.combiners.Prediction.value" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-surveyequivalence.scoring_functions">
<span id="scoring-functions"></span><h2>Scoring Functions<a class="headerlink" href="#module-surveyequivalence.scoring_functions" title="Permalink to this heading">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="surveyequivalence.scoring_functions.AUCScore">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">surveyequivalence.scoring_functions.</span></span><span class="sig-name descname"><span class="pre">AUCScore</span></span><a class="headerlink" href="#surveyequivalence.scoring_functions.AUCScore" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#surveyequivalence.scoring_functions.Scorer" title="surveyequivalence.scoring_functions.Scorer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Scorer</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="surveyequivalence.scoring_functions.AUCScore.score">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">classifier_predictions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#surveyequivalence.combiners.DiscreteDistributionPrediction" title="surveyequivalence.combiners.DiscreteDistributionPrediction"><span class="pre">DiscreteDistributionPrediction</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rater_labels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbosity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">float</span></span></span><a class="headerlink" href="#surveyequivalence.scoring_functions.AUCScore.score" title="Permalink to this definition">¶</a></dt>
<dd><p>AUC score. This function uses sklearn's AUC function, but does not work in many cases with multiple labels.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>classifier_predictions</strong> (<em>numeric values</em>) -- </p></li>
<li><p><strong>rater_labels</strong> (<em>sequence</em><em> of </em><em>labels</em><em>, </em><em>which should be numeric values</em>) -- </p></li>
<li><p><strong>verbosity</strong> -- </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>AUC Score</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="surveyequivalence.scoring_functions.AgreementScore">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">surveyequivalence.scoring_functions.</span></span><span class="sig-name descname"><span class="pre">AgreementScore</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_virtual_raters</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_ref_raters_per_virtual_rater</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ref_rater_combiner</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'majority_vote'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbosity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.scoring_functions.AgreementScore" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#surveyequivalence.scoring_functions.Scorer_for_Hard_Classifier" title="surveyequivalence.scoring_functions.Scorer_for_Hard_Classifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">Scorer_for_Hard_Classifier</span></code></a></p>
<p>Agreement Scorer. Discrete labels and predictions</p>
<dl class="py method">
<dt class="sig sig-object py" id="surveyequivalence.scoring_functions.AgreementScore.expected_score_anonymous_raters">
<span class="sig-name descname"><span class="pre">expected_score_anonymous_raters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">classifier_predictions</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">W</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_virtual_raters</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_ref_raters_per_virtual_rater</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ref_rater_combiner</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbosity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.scoring_functions.AgreementScore.expected_score_anonymous_raters" title="Permalink to this definition">¶</a></dt>
<dd><p>A virtual rater is a majority vote from a group of num_ref_raters_per_virtual_rater randomly selected non-null ratings.
Closed-form solution for the expectation, so we ignore the num_virtual_raters parameter</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>classifier_predictions</strong> (<em>Scoring predictions</em>) -- </p></li>
<li><p><strong>W</strong> (<em>The item and rating dataset</em>) -- </p></li>
<li><p><strong>verbosity</strong> (<em>verbosity value from 1 to 4 indicating increased verbosity.</em>) -- </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>A scalar expected score</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="surveyequivalence.scoring_functions.AgreementScore.score">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">classifier_predictions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#surveyequivalence.combiners.DiscretePrediction" title="surveyequivalence.combiners.DiscretePrediction"><span class="pre">DiscretePrediction</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rater_labels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbosity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.scoring_functions.AgreementScore.score" title="Permalink to this definition">¶</a></dt>
<dd><p>Agreement score measures the normalized number of times that the predictor matched the label. Akin to a typical
accuracy score.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>classifier_predictions</strong> (<em>numeric values</em>) -- </p></li>
<li><p><strong>rater_labels</strong> (<em>sequence</em><em> of </em><em>labels</em><em>, </em><em>which should be numeric values</em>) -- </p></li>
<li><p><strong>verbosity</strong> -- </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Agreement score</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="surveyequivalence.scoring_functions.Correlation">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">surveyequivalence.scoring_functions.</span></span><span class="sig-name descname"><span class="pre">Correlation</span></span><a class="headerlink" href="#surveyequivalence.scoring_functions.Correlation" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#surveyequivalence.scoring_functions.Scorer_for_Numeric_Classifier" title="surveyequivalence.scoring_functions.Scorer_for_Numeric_Classifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">Scorer_for_Numeric_Classifier</span></code></a></p>
<p>Computes the Pearson correlation coefficient.</p>
<dl class="py method">
<dt class="sig sig-object py" id="surveyequivalence.scoring_functions.Correlation.score">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">classifier_predictions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#surveyequivalence.combiners.NumericPrediction" title="surveyequivalence.combiners.NumericPrediction"><span class="pre">NumericPrediction</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rater_labels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbosity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.scoring_functions.Correlation.score" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>classifier_predictions</strong> (<em>numeric values</em>) -- </p></li>
<li><p><strong>rater_labels</strong> (<em>sequence</em><em> of </em><em>labels</em><em>, </em><em>which should be numeric values</em>) -- </p></li>
<li><p><strong>verbosity</strong> -- </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Pearson correlation coefficient</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="surveyequivalence.scoring_functions.CrossEntropyScore">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">surveyequivalence.scoring_functions.</span></span><span class="sig-name descname"><span class="pre">CrossEntropyScore</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_virtual_raters</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_ref_raters_per_virtual_rater</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ref_rater_combiner</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'majority_vote'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbosity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.scoring_functions.CrossEntropyScore" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#surveyequivalence.scoring_functions.Scorer_for_Soft_Classifier" title="surveyequivalence.scoring_functions.Scorer_for_Soft_Classifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">Scorer_for_Soft_Classifier</span></code></a></p>
<p>Cross Entropy Scorer</p>
<dl class="py method">
<dt class="sig sig-object py" id="surveyequivalence.scoring_functions.CrossEntropyScore.expected_score_anonymous_raters">
<span class="sig-name descname"><span class="pre">expected_score_anonymous_raters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">classifier_predictions</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">W</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_virtual_raters</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_ref_raters_per_virtual_rater</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ref_rater_combiner</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbosity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.scoring_functions.CrossEntropyScore.expected_score_anonymous_raters" title="Permalink to this definition">¶</a></dt>
<dd><p>A virtual rater is a majority vote from a group of num_ref_raters_per_virtual_rater randomly selected non-null ratings.
Closed-form solution for the expectation, so we ignore the num_virtual_raters parameter</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>classifier_predictions</strong> (<em>Scoring predictions</em>) -- </p></li>
<li><p><strong>W</strong> (<em>The item and rating dataset</em>) -- </p></li>
<li><p><strong>verbosity</strong> (<em>verbosity value from 1 to 4 indicating increased verbosity.</em>) -- </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>A scalar expected score</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="surveyequivalence.scoring_functions.CrossEntropyScore.score">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">classifier_predictions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#surveyequivalence.combiners.DiscreteDistributionPrediction" title="surveyequivalence.combiners.DiscreteDistributionPrediction"><span class="pre">DiscreteDistributionPrediction</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rater_labels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbosity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.scoring_functions.CrossEntropyScore.score" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculates the Cross Entropy of the two labels.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">CrossEntropyScore</span><span class="o">.</span><span class="n">score</span><span class="p">([</span><span class="n">DiscreteDistributionPrediction</span><span class="p">([</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">],</span> <span class="n">prs</span><span class="p">)</span> <span class="k">for</span> <span class="n">prs</span> <span class="ow">in</span> <span class="p">[[</span><span class="mf">.3</span><span class="p">,</span> <span class="mf">.7</span><span class="p">],</span> <span class="p">[</span><span class="mf">.4</span><span class="p">,</span> <span class="mf">.6</span><span class="p">],</span> <span class="p">[</span><span class="mf">.6</span><span class="p">,</span> <span class="mf">.4</span><span class="p">]]],</span>  <span class="p">[</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">])</span>
<span class="go">0.594597099859</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">CrossEntropyScore</span><span class="o">.</span><span class="n">score</span><span class="p">([</span><span class="n">DiscreteDistributionPrediction</span><span class="p">([</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">],</span> <span class="n">prs</span><span class="p">)</span> <span class="k">for</span> <span class="n">prs</span> <span class="ow">in</span> <span class="p">[[</span><span class="mf">.3</span><span class="p">,</span> <span class="mf">.7</span><span class="p">],</span> <span class="p">[</span><span class="mf">.4</span><span class="p">,</span> <span class="mf">.6</span><span class="p">],</span> <span class="p">[</span><span class="mf">.6</span><span class="p">,</span> <span class="mf">.4</span><span class="p">]]],</span>  <span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">])</span>
<span class="go">0.87702971998</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>classifier_predictions</strong> (<em>numeric values</em>) -- </p></li>
<li><p><strong>rater_labels</strong> (<em>sequence</em><em> of </em><em>labels</em><em>, </em><em>which should be numeric values</em>) -- </p></li>
<li><p><strong>verbosity</strong> -- </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Cross Entropy score</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="surveyequivalence.scoring_functions.DMIScore_for_Hard_Classifier">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">surveyequivalence.scoring_functions.</span></span><span class="sig-name descname"><span class="pre">DMIScore_for_Hard_Classifier</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_virtual_raters</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_ref_raters_per_virtual_rater</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ref_rater_combiner</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'majority_vote'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbosity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.scoring_functions.DMIScore_for_Hard_Classifier" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#surveyequivalence.scoring_functions.Scorer_for_Hard_Classifier" title="surveyequivalence.scoring_functions.Scorer_for_Hard_Classifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">Scorer_for_Hard_Classifier</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="surveyequivalence.scoring_functions.DMIScore_for_Hard_Classifier.expected_score_anonymous_raters">
<span class="sig-name descname"><span class="pre">expected_score_anonymous_raters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">classifier_predictions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#surveyequivalence.combiners.DiscretePrediction" title="surveyequivalence.combiners.DiscretePrediction"><span class="pre">DiscretePrediction</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">W</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_virtual_raters</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_ref_raters_per_virtual_rater</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ref_rater_combiner</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbosity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.scoring_functions.DMIScore_for_Hard_Classifier.expected_score_anonymous_raters" title="Permalink to this definition">¶</a></dt>
<dd><p>This implementation generates sample virtual raters, scores each, and takes the mean
Some scoring functions override this with a closed-form solution for the expectation</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>classifier_predictions</strong> (<em>Scoring predictions</em>) -- </p></li>
<li><p><strong>W</strong> (<em>The item and rating dataset</em>) -- </p></li>
<li><p><strong>num_virtual_raters</strong> (<em>(</em><em>the same with instance property if None</em><em>) </em><em>the number</em><em> of </em><em>virtual raters drawn when calculating the score. Higher num_virtural_rater makes the varience</em><em> of </em><em>score lower.</em>) -- </p></li>
<li><p><strong>num_ref_raters_per_virtual_rater</strong> (<em>(</em><em>the same with instance property if None</em><em>) </em><em>A virtual rater is the combined rating</em><em> of </em><em>a randomly selected set</em><em> of </em><em>num_ref_raters_per_virtual_rater non-null ratings for each column</em>) -- </p></li>
<li><p><strong>ref_rater_combiner</strong> (<em>(</em><em>the same with instance property if None</em><em>) </em><em>The way to combine the ref_raters. Default: Combine with majority vote for discrete labels; mean for continuous labels</em>) -- </p></li>
<li><p><strong>verbosity</strong> (<em>(</em><em>the same with instance property if None</em><em>) </em><em>verbosity value from 1 to 4 indicating increased verbosity.</em>) -- </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>A scalar expected score</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="surveyequivalence.scoring_functions.DMIScore_for_Hard_Classifier.score">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">classifier_predictions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#surveyequivalence.combiners.DiscretePrediction" title="surveyequivalence.combiners.DiscretePrediction"><span class="pre">DiscretePrediction</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rater_labels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbosity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">float</span></span></span><a class="headerlink" href="#surveyequivalence.scoring_functions.DMIScore_for_Hard_Classifier.score" title="Permalink to this definition">¶</a></dt>
<dd><p>DMI score.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>classifier_predictions</strong> (<em>the</em><em> (</em><em>hard</em><em>) </em><em>classifier's predictions for all items</em>) -- </p></li>
<li><p><strong>rater_labels</strong> (<em>sequence</em><em> of </em><em>labels from the reference rater</em>) -- </p></li>
<li><p><strong>verbosity</strong> -- </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>DMI Score</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="surveyequivalence.scoring_functions.DMIScore_for_Soft_Classifier">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">surveyequivalence.scoring_functions.</span></span><span class="sig-name descname"><span class="pre">DMIScore_for_Soft_Classifier</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_virtual_raters</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_ref_raters_per_virtual_rater</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ref_rater_combiner</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'majority_vote'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbosity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.scoring_functions.DMIScore_for_Soft_Classifier" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#surveyequivalence.scoring_functions.Scorer_for_Soft_Classifier" title="surveyequivalence.scoring_functions.Scorer_for_Soft_Classifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">Scorer_for_Soft_Classifier</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="surveyequivalence.scoring_functions.DMIScore_for_Soft_Classifier.expected_score_anonymous_raters">
<span class="sig-name descname"><span class="pre">expected_score_anonymous_raters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">classifier_predictions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#surveyequivalence.combiners.DiscreteDistributionPrediction" title="surveyequivalence.combiners.DiscreteDistributionPrediction"><span class="pre">DiscreteDistributionPrediction</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">W</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_virtual_raters</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_ref_raters_per_virtual_rater</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ref_rater_combiner</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbosity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.scoring_functions.DMIScore_for_Soft_Classifier.expected_score_anonymous_raters" title="Permalink to this definition">¶</a></dt>
<dd><p>This implementation generates sample virtual raters, scores each, and takes the mean
Some scoring functions override this with a closed-form solution for the expectation</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>classifier_predictions</strong> (<em>Scoring predictions</em>) -- </p></li>
<li><p><strong>W</strong> (<em>The item and rating dataset</em>) -- </p></li>
<li><p><strong>num_virtual_raters</strong> (<em>(</em><em>the same with instance property if None</em><em>) </em><em>the number</em><em> of </em><em>virtual raters drawn when calculating the score. Higher num_virtural_rater makes the varience</em><em> of </em><em>score lower.</em>) -- </p></li>
<li><p><strong>num_ref_raters_per_virtual_rater</strong> (<em>(</em><em>the same with instance property if None</em><em>) </em><em>A virtual rater is the combined rating</em><em> of </em><em>a randomly selected set</em><em> of </em><em>num_ref_raters_per_virtual_rater non-null ratings for each column</em>) -- </p></li>
<li><p><strong>ref_rater_combiner</strong> (<em>(</em><em>the same with instance property if None</em><em>) </em><em>The way to combine the ref_raters. Default: Combine with majority vote for discrete labels; mean for continuous labels</em>) -- </p></li>
<li><p><strong>verbosity</strong> (<em>(</em><em>the same with instance property if None</em><em>) </em><em>verbosity value from 1 to 4 indicating increased verbosity.</em>) -- </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>A scalar expected score</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="surveyequivalence.scoring_functions.DMIScore_for_Soft_Classifier.score">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">classifier_predictions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#surveyequivalence.combiners.DiscreteDistributionPrediction" title="surveyequivalence.combiners.DiscreteDistributionPrediction"><span class="pre">DiscreteDistributionPrediction</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rater_labels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbosity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">float</span></span></span><a class="headerlink" href="#surveyequivalence.scoring_functions.DMIScore_for_Soft_Classifier.score" title="Permalink to this definition">¶</a></dt>
<dd><p>DMI score.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>classifier_predictions</strong> (<em>the</em><em> (</em><em>soft</em><em>) </em><em>classifier's predictions for all items</em>) -- </p></li>
<li><p><strong>rater_labels</strong> (<em>sequence</em><em> of </em><em>labels from the reference rater</em>) -- </p></li>
<li><p><strong>verbosity</strong> -- </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>DMI Score</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="surveyequivalence.scoring_functions.F1Score">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">surveyequivalence.scoring_functions.</span></span><span class="sig-name descname"><span class="pre">F1Score</span></span><a class="headerlink" href="#surveyequivalence.scoring_functions.F1Score" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#surveyequivalence.scoring_functions.Scorer" title="surveyequivalence.scoring_functions.Scorer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Scorer</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="surveyequivalence.scoring_functions.F1Score.score">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">classifier_predictions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#surveyequivalence.combiners.DiscreteDistributionPrediction" title="surveyequivalence.combiners.DiscreteDistributionPrediction"><span class="pre">DiscreteDistributionPrediction</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rater_labels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbosity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">average</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'micro'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">float</span></span></span><a class="headerlink" href="#surveyequivalence.scoring_functions.F1Score.score" title="Permalink to this definition">¶</a></dt>
<dd><p>F1 score. This function uses sklearn's F1 function.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">F1Score</span><span class="o">.</span><span class="n">score</span><span class="p">([</span><span class="n">DiscreteDistributionPrediction</span><span class="p">([</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">],</span> <span class="n">prs</span><span class="p">)</span> <span class="k">for</span> <span class="n">prs</span> <span class="ow">in</span> <span class="p">[[</span><span class="mf">.3</span><span class="p">,</span> <span class="mf">.7</span><span class="p">],</span> <span class="p">[</span><span class="mf">.4</span><span class="p">,</span> <span class="mf">.6</span><span class="p">],</span> <span class="p">[</span><span class="mf">.6</span><span class="p">,</span> <span class="mf">.4</span><span class="p">]]],</span>  <span class="p">[</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">],</span> <span class="s1">&#39;micro&#39;</span><span class="p">)</span>
<span class="go">0.6666666666666666</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">F1Score</span><span class="o">.</span><span class="n">score</span><span class="p">([</span><span class="n">DiscreteDistributionPrediction</span><span class="p">([</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">],</span> <span class="n">prs</span><span class="p">)</span> <span class="k">for</span> <span class="n">prs</span> <span class="ow">in</span> <span class="p">[[</span><span class="mf">.3</span><span class="p">,</span> <span class="mf">.7</span><span class="p">],</span> <span class="p">[</span><span class="mf">.4</span><span class="p">,</span> <span class="mf">.6</span><span class="p">],</span> <span class="p">[</span><span class="mf">.6</span><span class="p">,</span> <span class="mf">.4</span><span class="p">]]],</span>  <span class="p">[</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">],</span> <span class="s1">&#39;macro&#39;</span><span class="p">)</span>
<span class="go">0.39759036144</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">F1Score</span><span class="o">.</span><span class="n">score</span><span class="p">([</span><span class="n">DiscreteDistributionPrediction</span><span class="p">([</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">],</span> <span class="n">prs</span><span class="p">)</span> <span class="k">for</span> <span class="n">prs</span> <span class="ow">in</span> <span class="p">[[</span><span class="mf">.3</span><span class="p">,</span> <span class="mf">.7</span><span class="p">],</span> <span class="p">[</span><span class="mf">.4</span><span class="p">,</span> <span class="mf">.6</span><span class="p">],</span> <span class="p">[</span><span class="mf">.6</span><span class="p">,</span> <span class="mf">.4</span><span class="p">]]],</span>  <span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">],</span> <span class="s1">&#39;micro&#39;</span><span class="p">)</span>
<span class="go">0.3333333333333333</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">F1Score</span><span class="o">.</span><span class="n">score</span><span class="p">([</span><span class="n">DiscreteDistributionPrediction</span><span class="p">([</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">],</span> <span class="n">prs</span><span class="p">)</span> <span class="k">for</span> <span class="n">prs</span> <span class="ow">in</span> <span class="p">[[</span><span class="mf">.3</span><span class="p">,</span> <span class="mf">.7</span><span class="p">],</span> <span class="p">[</span><span class="mf">.4</span><span class="p">,</span> <span class="mf">.6</span><span class="p">],</span> <span class="p">[</span><span class="mf">.6</span><span class="p">,</span> <span class="mf">.4</span><span class="p">]]],</span>  <span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">],</span> <span class="s1">&#39;macro&#39;</span><span class="p">)</span>
<span class="go">0.25</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>classifier_predictions</strong> (<em>numeric values</em>) -- </p></li>
<li><p><strong>rater_labels</strong> (<em>sequence</em><em> of </em><em>labels</em><em>, </em><em>which should be numeric values</em>) -- </p></li>
<li><p><strong>verbosity</strong> -- </p></li>
<li><p><strong>average</strong> (<em>macro</em><em> or </em><em>micro averaging</em>) -- </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>F1 Score</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="surveyequivalence.scoring_functions.PrecisionScore">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">surveyequivalence.scoring_functions.</span></span><span class="sig-name descname"><span class="pre">PrecisionScore</span></span><a class="headerlink" href="#surveyequivalence.scoring_functions.PrecisionScore" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#surveyequivalence.scoring_functions.Scorer" title="surveyequivalence.scoring_functions.Scorer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Scorer</span></code></a></p>
<p>Only implemented for binary labels where one of the labels is &quot;pos&quot; and binary predictions.
Calculate the expected probability of (pos rating | pos prediction).
(True positives divided by all positives).</p>
<dl class="py method">
<dt class="sig sig-object py" id="surveyequivalence.scoring_functions.PrecisionScore.expected_score_anonymous_raters">
<span class="sig-name descname"><span class="pre">expected_score_anonymous_raters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">classifier_predictions</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">W</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">positive_label</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'pos'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_virtual_raters</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbosity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.scoring_functions.PrecisionScore.expected_score_anonymous_raters" title="Permalink to this definition">¶</a></dt>
<dd><p>A virtual rater is a randomly selected non-null rating for each column.
Closed-form solution for the expectation, so we ignore the num_virtual_raters parameter</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>classifier_predictions</strong> (<em>Scoring predictions</em>) -- </p></li>
<li><p><strong>W</strong> (<em>The item and rating dataset</em>) -- </p></li>
<li><p><strong>positive_label</strong> (<em>the label for positive</em><em>, </em><em>default pos</em>) -- </p></li>
<li><p><strong>verbosity</strong> (<em>verbosity value from 1 to 4 indicating increased verbosity.</em>) -- </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>A scalar expected score</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="surveyequivalence.scoring_functions.PrecisionScore.score">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">classifier_predictions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#surveyequivalence.combiners.DiscreteDistributionPrediction" title="surveyequivalence.combiners.DiscreteDistributionPrediction"><span class="pre">DiscreteDistributionPrediction</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rater_labels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbosity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">average</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'micro'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">float</span></span></span><a class="headerlink" href="#surveyequivalence.scoring_functions.PrecisionScore.score" title="Permalink to this definition">¶</a></dt>
<dd><p>Precision score. This function uses sklearn's precision function.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">PrecisionScore</span><span class="o">.</span><span class="n">score</span><span class="p">([</span><span class="n">DiscreteDistributionPrediction</span><span class="p">([</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">],</span> <span class="n">prs</span><span class="p">)</span> <span class="k">for</span> <span class="n">prs</span> <span class="ow">in</span> <span class="p">[[</span><span class="mf">.3</span><span class="p">,</span> <span class="mf">.7</span><span class="p">],</span> <span class="p">[</span><span class="mf">.4</span><span class="p">,</span> <span class="mf">.6</span><span class="p">],</span> <span class="p">[</span><span class="mf">.6</span><span class="p">,</span> <span class="mf">.4</span><span class="p">]]],</span>  <span class="p">[</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">],</span> <span class="s1">&#39;micro&#39;</span><span class="p">)</span>
<span class="go">0.6666666666666666</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">PrecisionScore</span><span class="o">.</span><span class="n">score</span><span class="p">([</span><span class="n">DiscreteDistributionPrediction</span><span class="p">([</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">],</span> <span class="n">prs</span><span class="p">)</span> <span class="k">for</span> <span class="n">prs</span> <span class="ow">in</span> <span class="p">[[</span><span class="mf">.3</span><span class="p">,</span> <span class="mf">.7</span><span class="p">],</span> <span class="p">[</span><span class="mf">.4</span><span class="p">,</span> <span class="mf">.6</span><span class="p">],</span> <span class="p">[</span><span class="mf">.6</span><span class="p">,</span> <span class="mf">.4</span><span class="p">]]],</span>  <span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">],</span> <span class="s1">&#39;micro&#39;</span><span class="p">)</span>
<span class="go">0.3333333333333333</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>classifier_predictions</strong> (<em>numeric values</em>) -- </p></li>
<li><p><strong>rater_labels</strong> (<em>sequence</em><em> of </em><em>labels</em><em>, </em><em>which should be numeric values</em>) -- </p></li>
<li><p><strong>verbosity</strong> -- </p></li>
<li><p><strong>average</strong> (<em>macro</em><em> or </em><em>micro averaging</em>) -- </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Precision Score</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="surveyequivalence.scoring_functions.RecallScore">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">surveyequivalence.scoring_functions.</span></span><span class="sig-name descname"><span class="pre">RecallScore</span></span><a class="headerlink" href="#surveyequivalence.scoring_functions.RecallScore" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#surveyequivalence.scoring_functions.Scorer" title="surveyequivalence.scoring_functions.Scorer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Scorer</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="surveyequivalence.scoring_functions.RecallScore.score">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">classifier_predictions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#surveyequivalence.combiners.DiscreteDistributionPrediction" title="surveyequivalence.combiners.DiscreteDistributionPrediction"><span class="pre">DiscreteDistributionPrediction</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rater_labels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbosity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">average</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'micro'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">float</span></span></span><a class="headerlink" href="#surveyequivalence.scoring_functions.RecallScore.score" title="Permalink to this definition">¶</a></dt>
<dd><p>Recall score. This function uses sklearn's recall function.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">RecallScore</span><span class="o">.</span><span class="n">score</span><span class="p">([</span><span class="n">DiscreteDistributionPrediction</span><span class="p">([</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">],</span> <span class="n">prs</span><span class="p">)</span> <span class="k">for</span> <span class="n">prs</span> <span class="ow">in</span> <span class="p">[[</span><span class="mf">.3</span><span class="p">,</span> <span class="mf">.7</span><span class="p">],</span> <span class="p">[</span><span class="mf">.4</span><span class="p">,</span> <span class="mf">.6</span><span class="p">],</span> <span class="p">[</span><span class="mf">.6</span><span class="p">,</span> <span class="mf">.4</span><span class="p">]]],</span>  <span class="p">[</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">],</span> <span class="s1">&#39;micro&#39;</span><span class="p">)</span>
<span class="go">0.6666666666666666</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">RecallScore</span><span class="o">.</span><span class="n">score</span><span class="p">([</span><span class="n">DiscreteDistributionPrediction</span><span class="p">([</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">],</span> <span class="n">prs</span><span class="p">)</span> <span class="k">for</span> <span class="n">prs</span> <span class="ow">in</span> <span class="p">[[</span><span class="mf">.3</span><span class="p">,</span> <span class="mf">.7</span><span class="p">],</span> <span class="p">[</span><span class="mf">.4</span><span class="p">,</span> <span class="mf">.6</span><span class="p">],</span> <span class="p">[</span><span class="mf">.6</span><span class="p">,</span> <span class="mf">.4</span><span class="p">]]],</span>  <span class="p">[</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">],</span> <span class="s1">&#39;macro&#39;</span><span class="p">)</span>
<span class="go">0.5</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">RecallScore</span><span class="o">.</span><span class="n">score</span><span class="p">([</span><span class="n">DiscreteDistributionPrediction</span><span class="p">([</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">],</span> <span class="n">prs</span><span class="p">)</span> <span class="k">for</span> <span class="n">prs</span> <span class="ow">in</span> <span class="p">[[</span><span class="mf">.3</span><span class="p">,</span> <span class="mf">.7</span><span class="p">],</span> <span class="p">[</span><span class="mf">.4</span><span class="p">,</span> <span class="mf">.6</span><span class="p">],</span> <span class="p">[</span><span class="mf">.6</span><span class="p">,</span> <span class="mf">.4</span><span class="p">]]],</span>  <span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">],</span> <span class="s1">&#39;micro&#39;</span><span class="p">)</span>
<span class="go">0.3333333333333333</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">RecallScore</span><span class="o">.</span><span class="n">score</span><span class="p">([</span><span class="n">DiscreteDistributionPrediction</span><span class="p">([</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">],</span> <span class="n">prs</span><span class="p">)</span> <span class="k">for</span> <span class="n">prs</span> <span class="ow">in</span> <span class="p">[[</span><span class="mf">.3</span><span class="p">,</span> <span class="mf">.7</span><span class="p">],</span> <span class="p">[</span><span class="mf">.4</span><span class="p">,</span> <span class="mf">.6</span><span class="p">],</span> <span class="p">[</span><span class="mf">.6</span><span class="p">,</span> <span class="mf">.4</span><span class="p">]]],</span>  <span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">],</span> <span class="s1">&#39;macro&#39;</span><span class="p">)</span>
<span class="go">0.25</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>classifier_predictions</strong> (<em>numeric values</em>) -- </p></li>
<li><p><strong>rater_labels</strong> (<em>sequence</em><em> of </em><em>labels</em><em>, </em><em>which should be numeric values</em>) -- </p></li>
<li><p><strong>verbosity</strong> -- </p></li>
<li><p><strong>average</strong> (<em>macro</em><em> or </em><em>micro averaging</em>) -- </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Recall Score</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="surveyequivalence.scoring_functions.Scorer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">surveyequivalence.scoring_functions.</span></span><span class="sig-name descname"><span class="pre">Scorer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_virtual_raters</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_ref_raters_per_virtual_rater</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ref_rater_combiner</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'majority_vote'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbosity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.scoring_functions.Scorer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">ABC</span></code></p>
<p>Scorer Class. An abstract class.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_virtual_raters</strong> (<em>the number</em><em> of </em><em>virtual raters drawn when calculating the score. Higher num_virtural_rater makes the varience</em><em> of </em><em>score lower.</em>) -- </p></li>
<li><p><strong>num_ref_raters_per_virtual_rater</strong> (<em>A virtual rater is the combined rating</em><em> of </em><em>a randomly selected set</em><em> of </em><em>num_ref_raters_per_virtual_rater non-null ratings for each column</em>) -- </p></li>
<li><p><strong>ref_rater_combiner</strong> (<em>The way to combine the ref_raters. Default: Combine with majority vote for discrete labels; mean for continuous labels</em>) -- </p></li>
<li><p><strong>verbosity</strong> (<em>verbosity value from 1 to 4 indicating increased verbosity.</em>) -- </p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="surveyequivalence.scoring_functions.Scorer.expected_score">
<span class="sig-name descname"><span class="pre">expected_score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">classifier_predictions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">raters</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">W</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">anonymous</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbosity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.scoring_functions.Scorer.expected_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the expected score of the classifier against a random rater.
With anonymous flag, compute expected score against a randomly selected label for each item
With non-anonymous, compute the expected score against a randomly selected column.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>classifier_predictions</strong> (<em>Predictions to be scored</em>) -- </p></li>
<li><p><strong>raters</strong> (<em>Which columns</em><em> of </em><em>W to use as reference raters to score the predictions against</em>) -- </p></li>
<li><p><strong>W</strong> (<em>The item and rating dataset.</em>) -- </p></li>
<li><p><strong>anonymous</strong> (<em>if False</em><em>, </em><em>then a random rater is a column from W; if True</em><em>, </em><em>then labels in a column are</em>) -- not necessarily from the same rater.</p></li>
<li><p><strong>verbosity</strong> (<em>(</em><em>the same with instance property if None</em><em>) </em><em>verbosity value from 1 to 4 indicating increased printed feedback during execution.</em>) -- </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Expected score of the classifier against a random rater.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="surveyequivalence.scoring_functions.Scorer.expected_score_anonymous_raters">
<span class="sig-name descname"><span class="pre">expected_score_anonymous_raters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">classifier_predictions</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">W</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_virtual_raters</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_ref_raters_per_virtual_rater</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ref_rater_combiner</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbosity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.scoring_functions.Scorer.expected_score_anonymous_raters" title="Permalink to this definition">¶</a></dt>
<dd><p>This implementation generates sample virtual raters, scores each, and takes the mean
Some scoring functions override this with a closed-form solution for the expectation</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>classifier_predictions</strong> (<em>Scoring predictions</em>) -- </p></li>
<li><p><strong>W</strong> (<em>The item and rating dataset</em>) -- </p></li>
<li><p><strong>num_virtual_raters</strong> (<em>(</em><em>the same with instance property if None</em><em>) </em><em>the number</em><em> of </em><em>virtual raters drawn when calculating the score. Higher num_virtural_rater makes the varience</em><em> of </em><em>score lower.</em>) -- </p></li>
<li><p><strong>num_ref_raters_per_virtual_rater</strong> (<em>(</em><em>the same with instance property if None</em><em>) </em><em>A virtual rater is the combined rating</em><em> of </em><em>a randomly selected set</em><em> of </em><em>num_ref_raters_per_virtual_rater non-null ratings for each column</em>) -- </p></li>
<li><p><strong>ref_rater_combiner</strong> (<em>(</em><em>the same with instance property if None</em><em>) </em><em>The way to combine the ref_raters. Default: Combine with majority vote for discrete labels; mean for continuous labels</em>) -- </p></li>
<li><p><strong>verbosity</strong> (<em>(</em><em>the same with instance property if None</em><em>) </em><em>verbosity value from 1 to 4 indicating increased verbosity.</em>) -- </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>A scalar expected score</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="surveyequivalence.scoring_functions.Scorer.expected_score_non_anonymous_raters">
<span class="sig-name descname"><span class="pre">expected_score_non_anonymous_raters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">classifier_predictions</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">W</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbosity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.scoring_functions.Scorer.expected_score_non_anonymous_raters" title="Permalink to this definition">¶</a></dt>
<dd><p>A virtual rater is a column of W</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>classifier_predictions</strong> (<em>Scoring predictions</em>) -- </p></li>
<li><p><strong>W</strong> (<em>The item and rating dataset</em>) -- </p></li>
<li><p><strong>verbosity</strong> (<em>(</em><em>the same with instance property if None</em><em>) </em><em>verbosity value from 1 to 4 indicating increased verbosity.</em>) -- </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>A scalar expected score</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="surveyequivalence.scoring_functions.Scorer.score">
<em class="property"><span class="pre">abstract</span><span class="w"> </span><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">classifier_predictions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rater_labels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">float</span></span></span><a class="headerlink" href="#surveyequivalence.scoring_functions.Scorer.score" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="surveyequivalence.scoring_functions.Scorer_for_Hard_Classifier">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">surveyequivalence.scoring_functions.</span></span><span class="sig-name descname"><span class="pre">Scorer_for_Hard_Classifier</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_virtual_raters</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_ref_raters_per_virtual_rater</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ref_rater_combiner</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'majority_vote'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbosity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.scoring_functions.Scorer_for_Hard_Classifier" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#surveyequivalence.scoring_functions.Scorer" title="surveyequivalence.scoring_functions.Scorer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Scorer</span></code></a></p>
<p>Scorer class for hard classifier (whose output is a DiscretePrediction)</p>
<p>Computes numeric socre for a sequence of classifier DiscretePredictions:
- .score() yields actual score against a sequence of reference labels
- .expected_score() yields expected score against a matrix of reference labels</p>
<p>Note that the current implementation of survey equivalence centering on c_0 and plotting
both assume that higher scores are better.</p>
<dl class="py method">
<dt class="sig sig-object py" id="surveyequivalence.scoring_functions.Scorer_for_Hard_Classifier.expected_score">
<span class="sig-name descname"><span class="pre">expected_score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">classifier_predictions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#surveyequivalence.combiners.DiscretePrediction" title="surveyequivalence.combiners.DiscretePrediction"><span class="pre">DiscretePrediction</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">raters</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">W</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">anonymous</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbosity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.scoring_functions.Scorer_for_Hard_Classifier.expected_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the expected score of the classifier against a random rater.
With anonymous flag, compute expected score against a randomly selected label for each item
With non-anonymous, compute the expected score against a randomly selected column.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>classifier_predictions</strong> (<em>Predictions to be scored</em>) -- </p></li>
<li><p><strong>raters</strong> (<em>Which columns</em><em> of </em><em>W to use as reference raters to score the predictions against</em>) -- </p></li>
<li><p><strong>W</strong> (<em>The item and rating dataset.</em>) -- </p></li>
<li><p><strong>anonymous</strong> (<em>if False</em><em>, </em><em>then a random rater is a column from W; if True</em><em>, </em><em>then labels in a column are</em>) -- not necessarily from the same rater.</p></li>
<li><p><strong>verbosity</strong> (<em>(</em><em>the same with instance property if None</em><em>) </em><em>verbosity value from 1 to 4 indicating increased printed feedback during execution.</em>) -- </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Expected score of the classifier against a random rater.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="surveyequivalence.scoring_functions.Scorer_for_Hard_Classifier.expected_score_anonymous_raters">
<span class="sig-name descname"><span class="pre">expected_score_anonymous_raters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">classifier_predictions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#surveyequivalence.combiners.DiscretePrediction" title="surveyequivalence.combiners.DiscretePrediction"><span class="pre">DiscretePrediction</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">W</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_virtual_raters</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_ref_raters_per_virtual_rater</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ref_rater_combiner</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbosity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.scoring_functions.Scorer_for_Hard_Classifier.expected_score_anonymous_raters" title="Permalink to this definition">¶</a></dt>
<dd><p>This implementation generates sample virtual raters, scores each, and takes the mean
Some scoring functions override this with a closed-form solution for the expectation</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>classifier_predictions</strong> (<em>Scoring predictions</em>) -- </p></li>
<li><p><strong>W</strong> (<em>The item and rating dataset</em>) -- </p></li>
<li><p><strong>num_virtual_raters</strong> (<em>(</em><em>the same with instance property if None</em><em>) </em><em>the number</em><em> of </em><em>virtual raters drawn when calculating the score. Higher num_virtural_rater makes the varience</em><em> of </em><em>score lower.</em>) -- </p></li>
<li><p><strong>num_ref_raters_per_virtual_rater</strong> (<em>(</em><em>the same with instance property if None</em><em>) </em><em>A virtual rater is the combined rating</em><em> of </em><em>a randomly selected set</em><em> of </em><em>num_ref_raters_per_virtual_rater non-null ratings for each column</em>) -- </p></li>
<li><p><strong>ref_rater_combiner</strong> (<em>(</em><em>the same with instance property if None</em><em>) </em><em>The way to combine the ref_raters. Default: Combine with majority vote for discrete labels; mean for continuous labels</em>) -- </p></li>
<li><p><strong>verbosity</strong> (<em>(</em><em>the same with instance property if None</em><em>) </em><em>verbosity value from 1 to 4 indicating increased verbosity.</em>) -- </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>A scalar expected score</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="surveyequivalence.scoring_functions.Scorer_for_Hard_Classifier.expected_score_non_anonymous_raters">
<span class="sig-name descname"><span class="pre">expected_score_non_anonymous_raters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">classifier_predictions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#surveyequivalence.combiners.DiscretePrediction" title="surveyequivalence.combiners.DiscretePrediction"><span class="pre">DiscretePrediction</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">W</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbosity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.scoring_functions.Scorer_for_Hard_Classifier.expected_score_non_anonymous_raters" title="Permalink to this definition">¶</a></dt>
<dd><p>A virtual rater is a column of W</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>classifier_predictions</strong> (<em>Scoring predictions</em>) -- </p></li>
<li><p><strong>W</strong> (<em>The item and rating dataset</em>) -- </p></li>
<li><p><strong>verbosity</strong> (<em>(</em><em>the same with instance property if None</em><em>) </em><em>verbosity value from 1 to 4 indicating increased verbosity.</em>) -- </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>A scalar expected score</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="surveyequivalence.scoring_functions.Scorer_for_Hard_Classifier.score">
<em class="property"><span class="pre">abstract</span><span class="w"> </span><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">classifier_predictions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#surveyequivalence.combiners.DiscretePrediction" title="surveyequivalence.combiners.DiscretePrediction"><span class="pre">DiscretePrediction</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rater_labels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">float</span></span></span><a class="headerlink" href="#surveyequivalence.scoring_functions.Scorer_for_Hard_Classifier.score" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="surveyequivalence.scoring_functions.Scorer_for_Numeric_Classifier">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">surveyequivalence.scoring_functions.</span></span><span class="sig-name descname"><span class="pre">Scorer_for_Numeric_Classifier</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_virtual_raters</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_ref_raters_per_virtual_rater</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ref_rater_combiner</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbosity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.scoring_functions.Scorer_for_Numeric_Classifier" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#surveyequivalence.scoring_functions.Scorer" title="surveyequivalence.scoring_functions.Scorer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Scorer</span></code></a></p>
<p>Scorer class for numeric classifier (whose output is a NumericPrediction)</p>
<p>Computes numeric socre for a sequence of classifier NumericPredictions:
- .score() yields actual score against a sequence of reference labels
- .expected_score() yields expected score against a matrix of reference labels</p>
<p>Note that the current implementation of survey equivalence centering on c_0 and plotting
both assume that higher scores are better. Currently, this only affects the CrossEntropy scorer,
which we have negated from the traditional definition.</p>
<dl class="py method">
<dt class="sig sig-object py" id="surveyequivalence.scoring_functions.Scorer_for_Numeric_Classifier.expected_score">
<span class="sig-name descname"><span class="pre">expected_score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">classifier_predictions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#surveyequivalence.combiners.NumericPrediction" title="surveyequivalence.combiners.NumericPrediction"><span class="pre">NumericPrediction</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">raters</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">W</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">anonymous</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbosity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.scoring_functions.Scorer_for_Numeric_Classifier.expected_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the expected score of the classifier against a random rater.
With anonymous flag, compute expected score against a randomly selected label for each item
With non-anonymous, compute the expected score against a randomly selected column.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>classifier_predictions</strong> (<em>Predictions to be scored</em>) -- </p></li>
<li><p><strong>raters</strong> (<em>Which columns</em><em> of </em><em>W to use as reference raters to score the predictions against</em>) -- </p></li>
<li><p><strong>W</strong> (<em>The item and rating dataset.</em>) -- </p></li>
<li><p><strong>anonymous</strong> (<em>if False</em><em>, </em><em>then a random rater is a column from W; if True</em><em>, </em><em>then labels in a column are</em>) -- not necessarily from the same rater.</p></li>
<li><p><strong>verbosity</strong> (<em>(</em><em>the same with instance property if None</em><em>) </em><em>verbosity value from 1 to 4 indicating increased printed feedback during execution.</em>) -- </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Expected score of the classifier against a random rater.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="surveyequivalence.scoring_functions.Scorer_for_Numeric_Classifier.expected_score_anonymous_raters">
<span class="sig-name descname"><span class="pre">expected_score_anonymous_raters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">classifier_predictions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#surveyequivalence.combiners.NumericPrediction" title="surveyequivalence.combiners.NumericPrediction"><span class="pre">NumericPrediction</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">W</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_virtual_raters</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_ref_raters_per_virtual_rater</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ref_rater_combiner</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbosity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.scoring_functions.Scorer_for_Numeric_Classifier.expected_score_anonymous_raters" title="Permalink to this definition">¶</a></dt>
<dd><p>This implementation generates sample virtual raters, scores each, and takes the mean
Some scoring functions override this with a closed-form solution for the expectation</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>classifier_predictions</strong> (<em>Scoring predictions</em>) -- </p></li>
<li><p><strong>W</strong> (<em>The item and rating dataset</em>) -- </p></li>
<li><p><strong>num_virtual_raters</strong> (<em>(</em><em>the same with instance property if None</em><em>) </em><em>the number</em><em> of </em><em>virtual raters drawn when calculating the score. Higher num_virtural_rater makes the varience</em><em> of </em><em>score lower.</em>) -- </p></li>
<li><p><strong>num_ref_raters_per_virtual_rater</strong> (<em>(</em><em>the same with instance property if None</em><em>) </em><em>A virtual rater is the combined rating</em><em> of </em><em>a randomly selected set</em><em> of </em><em>num_ref_raters_per_virtual_rater non-null ratings for each column</em>) -- </p></li>
<li><p><strong>ref_rater_combiner</strong> (<em>(</em><em>the same with instance property if None</em><em>) </em><em>The way to combine the ref_raters. Default: Combine with majority vote for discrete labels; mean for continuous labels</em>) -- </p></li>
<li><p><strong>verbosity</strong> (<em>(</em><em>the same with instance property if None</em><em>) </em><em>verbosity value from 1 to 4 indicating increased verbosity.</em>) -- </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>A scalar expected score</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="surveyequivalence.scoring_functions.Scorer_for_Numeric_Classifier.expected_score_non_anonymous_raters">
<span class="sig-name descname"><span class="pre">expected_score_non_anonymous_raters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">classifier_predictions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#surveyequivalence.combiners.NumericPrediction" title="surveyequivalence.combiners.NumericPrediction"><span class="pre">NumericPrediction</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">W</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbosity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.scoring_functions.Scorer_for_Numeric_Classifier.expected_score_non_anonymous_raters" title="Permalink to this definition">¶</a></dt>
<dd><p>A virtual rater is a column of W</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>classifier_predictions</strong> (<em>Scoring predictions</em>) -- </p></li>
<li><p><strong>W</strong> (<em>The item and rating dataset</em>) -- </p></li>
<li><p><strong>verbosity</strong> (<em>(</em><em>the same with instance property if None</em><em>) </em><em>verbosity value from 1 to 4 indicating increased verbosity.</em>) -- </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>A scalar expected score</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="surveyequivalence.scoring_functions.Scorer_for_Numeric_Classifier.score">
<em class="property"><span class="pre">abstract</span><span class="w"> </span><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">classifier_predictions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#surveyequivalence.combiners.NumericPrediction" title="surveyequivalence.combiners.NumericPrediction"><span class="pre">NumericPrediction</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rater_labels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">float</span></span></span><a class="headerlink" href="#surveyequivalence.scoring_functions.Scorer_for_Numeric_Classifier.score" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="surveyequivalence.scoring_functions.Scorer_for_Soft_Classifier">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">surveyequivalence.scoring_functions.</span></span><span class="sig-name descname"><span class="pre">Scorer_for_Soft_Classifier</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_virtual_raters</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_ref_raters_per_virtual_rater</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ref_rater_combiner</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'majority_vote'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbosity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.scoring_functions.Scorer_for_Soft_Classifier" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#surveyequivalence.scoring_functions.Scorer" title="surveyequivalence.scoring_functions.Scorer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Scorer</span></code></a></p>
<p>Scorer class for soft classifier (whose output is a DiscreteDistributionPrediction)</p>
<p>Computes numeric socre for a sequence of classifier DiscreteDistributionPredictions:
- .score() yields actual score against a sequence of reference labels
- .expected_score() yields expected score against a matrix of reference labels</p>
<p>Note that the current implementation of survey equivalence centering on c_0 and plotting
both assume that higher scores are better. Currently, this only affects the CrossEntropy scorer,
which we have negated from the traditional definition.</p>
<dl class="py method">
<dt class="sig sig-object py" id="surveyequivalence.scoring_functions.Scorer_for_Soft_Classifier.expected_score">
<span class="sig-name descname"><span class="pre">expected_score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">classifier_predictions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#surveyequivalence.combiners.DiscreteDistributionPrediction" title="surveyequivalence.combiners.DiscreteDistributionPrediction"><span class="pre">DiscreteDistributionPrediction</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">raters</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">W</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">anonymous</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbosity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.scoring_functions.Scorer_for_Soft_Classifier.expected_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the expected score of the classifier against a random rater.
With anonymous flag, compute expected score against a randomly selected label for each item
With non-anonymous, compute the expected score against a randomly selected column.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>classifier_predictions</strong> (<em>Predictions to be scored</em>) -- </p></li>
<li><p><strong>raters</strong> (<em>Which columns</em><em> of </em><em>W to use as reference raters to score the predictions against</em>) -- </p></li>
<li><p><strong>W</strong> (<em>The item and rating dataset.</em>) -- </p></li>
<li><p><strong>anonymous</strong> (<em>if False</em><em>, </em><em>then a random rater is a column from W; if True</em><em>, </em><em>then labels in a column are</em>) -- not necessarily from the same rater.</p></li>
<li><p><strong>verbosity</strong> (<em>(</em><em>the same with instance property if None</em><em>) </em><em>verbosity value from 1 to 4 indicating increased printed feedback during execution.</em>) -- </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Expected score of the classifier against a random rater.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="surveyequivalence.scoring_functions.Scorer_for_Soft_Classifier.expected_score_anonymous_raters">
<span class="sig-name descname"><span class="pre">expected_score_anonymous_raters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">classifier_predictions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#surveyequivalence.combiners.DiscreteDistributionPrediction" title="surveyequivalence.combiners.DiscreteDistributionPrediction"><span class="pre">DiscreteDistributionPrediction</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">W</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_virtual_raters</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_ref_raters_per_virtual_rater</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ref_rater_combiner</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbosity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.scoring_functions.Scorer_for_Soft_Classifier.expected_score_anonymous_raters" title="Permalink to this definition">¶</a></dt>
<dd><p>This implementation generates sample virtual raters, scores each, and takes the mean
Some scoring functions override this with a closed-form solution for the expectation</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>classifier_predictions</strong> (<em>Scoring predictions</em>) -- </p></li>
<li><p><strong>W</strong> (<em>The item and rating dataset</em>) -- </p></li>
<li><p><strong>num_virtual_raters</strong> (<em>(</em><em>the same with instance property if None</em><em>) </em><em>the number</em><em> of </em><em>virtual raters drawn when calculating the score. Higher num_virtural_rater makes the varience</em><em> of </em><em>score lower.</em>) -- </p></li>
<li><p><strong>num_ref_raters_per_virtual_rater</strong> (<em>(</em><em>the same with instance property if None</em><em>) </em><em>A virtual rater is the combined rating</em><em> of </em><em>a randomly selected set</em><em> of </em><em>num_ref_raters_per_virtual_rater non-null ratings for each column</em>) -- </p></li>
<li><p><strong>ref_rater_combiner</strong> (<em>(</em><em>the same with instance property if None</em><em>) </em><em>The way to combine the ref_raters. Default: Combine with majority vote for discrete labels; mean for continuous labels</em>) -- </p></li>
<li><p><strong>verbosity</strong> (<em>(</em><em>the same with instance property if None</em><em>) </em><em>verbosity value from 1 to 4 indicating increased verbosity.</em>) -- </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>A scalar expected score</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="surveyequivalence.scoring_functions.Scorer_for_Soft_Classifier.expected_score_non_anonymous_raters">
<span class="sig-name descname"><span class="pre">expected_score_non_anonymous_raters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">classifier_predictions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#surveyequivalence.combiners.DiscreteDistributionPrediction" title="surveyequivalence.combiners.DiscreteDistributionPrediction"><span class="pre">DiscreteDistributionPrediction</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">W</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbosity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.scoring_functions.Scorer_for_Soft_Classifier.expected_score_non_anonymous_raters" title="Permalink to this definition">¶</a></dt>
<dd><p>A virtual rater is a column of W</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>classifier_predictions</strong> (<em>Scoring predictions</em>) -- </p></li>
<li><p><strong>W</strong> (<em>The item and rating dataset</em>) -- </p></li>
<li><p><strong>verbosity</strong> (<em>(</em><em>the same with instance property if None</em><em>) </em><em>verbosity value from 1 to 4 indicating increased verbosity.</em>) -- </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>A scalar expected score</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="surveyequivalence.scoring_functions.Scorer_for_Soft_Classifier.score">
<em class="property"><span class="pre">abstract</span><span class="w"> </span><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">classifier_predictions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#surveyequivalence.combiners.DiscreteDistributionPrediction" title="surveyequivalence.combiners.DiscreteDistributionPrediction"><span class="pre">DiscreteDistributionPrediction</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rater_labels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">float</span></span></span><a class="headerlink" href="#surveyequivalence.scoring_functions.Scorer_for_Soft_Classifier.score" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="surveyequivalence.scoring_functions.comb">
<span class="sig-prename descclassname"><span class="pre">surveyequivalence.scoring_functions.</span></span><span class="sig-name descname"><span class="pre">comb</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">m</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.scoring_functions.comb" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the combination number: pick m items from n items</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="surveyequivalence.scoring_functions.frac">
<span class="sig-prename descclassname"><span class="pre">surveyequivalence.scoring_functions.</span></span><span class="sig-name descname"><span class="pre">frac</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.scoring_functions.frac" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the frac: n!</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="surveyequivalence.scoring_functions.mode">
<span class="sig-prename descclassname"><span class="pre">surveyequivalence.scoring_functions.</span></span><span class="sig-name descname"><span class="pre">mode</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.scoring_functions.mode" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the mode in the data.</p>
</dd></dl>

</section>
<section id="synthetic-dataset-generation">
<h2>Synthetic Dataset Generation<a class="headerlink" href="#synthetic-dataset-generation" title="Permalink to this heading">¶</a></h2>
<section id="states">
<h3>States<a class="headerlink" href="#states" title="Permalink to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="surveyequivalence.synthetic_datasets.DiscreteState">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">surveyequivalence.synthetic_datasets.</span></span><span class="sig-name descname"><span class="pre">DiscreteState</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">probabilities</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.synthetic_datasets.DiscreteState" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">State</span></code></p>
<p>A discrete distribution over possible labels</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>state_name</strong> -- </p></li>
<li><p><strong>labels</strong> -- A sequence of strings; the allowable labels</p></li>
<li><p><strong>probabilities</strong> -- A sequence of the same length, with values adding to one, giving probabilities for each of the label strings</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="surveyequivalence.synthetic_datasets.DiscreteState.draw_labels">
<span class="sig-name descname"><span class="pre">draw_labels</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.synthetic_datasets.DiscreteState.draw_labels" title="Permalink to this definition">¶</a></dt>
<dd><p>Make n iid draws of discrete labels from the distribution</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>n</strong> -- How many labels to draw from the distribution</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>a single item or a numpy array</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="distributions-over-states">
<h3>Distributions Over States<a class="headerlink" href="#distributions-over-states" title="Permalink to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="surveyequivalence.synthetic_datasets.DistributionOverStates">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">surveyequivalence.synthetic_datasets.</span></span><span class="sig-name descname"><span class="pre">DistributionOverStates</span></span><a class="headerlink" href="#surveyequivalence.synthetic_datasets.DistributionOverStates" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">ABC</span></code></p>
<p>Abstract base class</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="surveyequivalence.synthetic_datasets.DiscreteDistributionOverStates">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">surveyequivalence.synthetic_datasets.</span></span><span class="sig-name descname"><span class="pre">DiscreteDistributionOverStates</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">states</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">State</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">probabilities</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.synthetic_datasets.DiscreteDistributionOverStates" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#surveyequivalence.synthetic_datasets.DistributionOverStates" title="surveyequivalence.synthetic_datasets.DistributionOverStates"><code class="xref py py-class docutils literal notranslate"><span class="pre">DistributionOverStates</span></code></a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>states</strong> -- a sequence of State objects</p></li>
<li><p><strong>probabilities</strong> -- a same length sequence of floats representing probabilities of the item states</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="surveyequivalence.synthetic_datasets.DiscreteDistributionOverStates.draw_states">
<span class="sig-name descname"><span class="pre">draw_states</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#surveyequivalence.synthetic_datasets.DiscreteState" title="surveyequivalence.synthetic_datasets.DiscreteState"><span class="pre">DiscreteState</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#surveyequivalence.synthetic_datasets.DiscreteDistributionOverStates.draw_states" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>n</strong> -- </p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>a single item or numpy array of State instances, drawn iid from the probability distribution</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="surveyequivalence.synthetic_datasets.FixedStateGenerator">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">surveyequivalence.synthetic_datasets.</span></span><span class="sig-name descname"><span class="pre">FixedStateGenerator</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">states</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">State</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">probabilities</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.synthetic_datasets.FixedStateGenerator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#surveyequivalence.synthetic_datasets.DiscreteDistributionOverStates" title="surveyequivalence.synthetic_datasets.DiscreteDistributionOverStates"><code class="xref py py-class docutils literal notranslate"><span class="pre">DiscreteDistributionOverStates</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="surveyequivalence.synthetic_datasets.FixedStateGenerator.draw_states">
<span class="sig-name descname"><span class="pre">draw_states</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.synthetic_datasets.FixedStateGenerator.draw_states" title="Permalink to this definition">¶</a></dt>
<dd><p>Draw exactly in proportion to probabilities, rather than each draw random according to the probabilities
:param n: How many items to draw</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list of State instances</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="mock-classifiers">
<h3>Mock Classifiers<a class="headerlink" href="#mock-classifiers" title="Permalink to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="surveyequivalence.synthetic_datasets.MockClassifier">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">surveyequivalence.synthetic_datasets.</span></span><span class="sig-name descname"><span class="pre">MockClassifier</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label_predictors</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="#surveyequivalence.combiners.Prediction" title="surveyequivalence.combiners.Prediction"><span class="pre">Prediction</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.synthetic_datasets.MockClassifier" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>A mock classifier has access to each item's state when generating a prediction,
something that a real classifier would not have access to</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> -- </p></li>
<li><p><strong>label_predictions</strong> -- a dictionary mapping from item state names to Predictions</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="surveyequivalence.synthetic_datasets.MockClassifier.make_predictions">
<span class="sig-name descname"><span class="pre">make_predictions</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">item_states</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">State</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#surveyequivalence.combiners.Prediction" title="surveyequivalence.combiners.Prediction"><span class="pre">Prediction</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#surveyequivalence.synthetic_datasets.MockClassifier.make_predictions" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>item_states</strong> -- a sequence of State objects, representing the states of some items</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>a sequence of Prediction objects, one for each item</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="surveyequivalence.synthetic_datasets.MappedDiscreteMockClassifier">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">surveyequivalence.synthetic_datasets.</span></span><span class="sig-name descname"><span class="pre">MappedDiscreteMockClassifier</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label_predictors</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="#surveyequivalence.combiners.Prediction" title="surveyequivalence.combiners.Prediction"><span class="pre">Prediction</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prediction_map</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="#surveyequivalence.combiners.Prediction" title="surveyequivalence.combiners.Prediction"><span class="pre">Prediction</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.synthetic_datasets.MappedDiscreteMockClassifier" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#surveyequivalence.synthetic_datasets.MockClassifier" title="surveyequivalence.synthetic_datasets.MockClassifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">MockClassifier</span></code></a></p>
<p>A mock classifier that maps an item state to a Prediction,     draws a discrete label from that,     and then maps that discrete label to another Prediction.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> -- </p></li>
<li><p><strong>label_predictions</strong> -- a dictionary mapping from item state names to Predictions</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="surveyequivalence.synthetic_datasets.MappedDiscreteMockClassifier.make_predictions">
<span class="sig-name descname"><span class="pre">make_predictions</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">item_states</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.synthetic_datasets.MappedDiscreteMockClassifier.make_predictions" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>item_states</strong> -- a sequence of State objects, representing the states of some items</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>a sequence of Prediction objects, one for each item</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="dataset-generators">
<h3>Dataset Generators<a class="headerlink" href="#dataset-generators" title="Permalink to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="surveyequivalence.synthetic_datasets.SyntheticDatasetGenerator">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">surveyequivalence.synthetic_datasets.</span></span><span class="sig-name descname"><span class="pre">SyntheticDatasetGenerator</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">item_state_generator</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#surveyequivalence.synthetic_datasets.DistributionOverStates" title="surveyequivalence.synthetic_datasets.DistributionOverStates"><span class="pre">DistributionOverStates</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_items_per_dataset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_labels_per_item</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_labels_per_item</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mock_classifiers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.synthetic_datasets.SyntheticDatasetGenerator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Generator for a set of items with some raters per item.
Items are defined by States, which are drawn from a DistributionOverStates.
Each State is a distribution over labels.
Each label is an i.i.d. draw from the State</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>item_state_generator</strong> -- </p></li>
<li><p><strong>num_items_per_dataset</strong> -- </p></li>
<li><p><strong>num_labels_per_item</strong> -- How many raters to generate labels for, for each item</p></li>
<li><p><strong>mock_classifiers</strong> -- A list of MockClassifier instances, which generate label predictions based on the item state</p></li>
<li><p><strong>name</strong> -- A text string naming this dataset generator</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="surveyequivalence.synthetic_datasets.SyntheticDatasetGenerator.generate_labels">
<span class="sig-name descname"><span class="pre">generate_labels</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">item_states</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_labels_per_item</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_labels_per_item</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rater_prefix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'e'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.synthetic_datasets.SyntheticDatasetGenerator.generate_labels" title="Permalink to this definition">¶</a></dt>
<dd><p>Normally called with item_states=self.reference_rater_item_states</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>self</strong> -- </p></li>
<li><p><strong>item_states</strong> -- a list of States, one for each item</p></li>
<li><p><strong>num_labels_per_item=None</strong> -- if None, use self.num_labels_per_item</p></li>
<li><p><strong>rater_prefix=&quot;e&quot;</strong> -- Rater columns are named as <cite>f&quot;{rater_prefix}_{i}&quot;</cite> where i is an integer</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>A pandas DataFrame with one row for each item and one column for each rater. Cells are labels.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="surveyequivalence.synthetic_datasets.SyntheticBinaryDatasetGenerator">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">surveyequivalence.synthetic_datasets.</span></span><span class="sig-name descname"><span class="pre">SyntheticBinaryDatasetGenerator</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">item_state_generator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_items_per_dataset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">50</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_labels_per_item</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_labels_per_item</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mock_classifiers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pct_noise</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k_other_raters_per_label</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.synthetic_datasets.SyntheticBinaryDatasetGenerator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#surveyequivalence.synthetic_datasets.SyntheticDatasetGenerator" title="surveyequivalence.synthetic_datasets.SyntheticDatasetGenerator"><code class="xref py py-class docutils literal notranslate"><span class="pre">SyntheticDatasetGenerator</span></code></a></p>
<p>Dataset generator for binary labels</p>
<p>Only additional parameters for this subclass are documented here.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pct_noise=0</strong> -- In addition to the reference rater labels, this generator can generator labels from &quot;other&quot; raters.         With probability pct_noise the binary labels will be drawn from a 50-50 coin flip, and otherwise from        the item's State.
If pct_noise==0, the other raters' labels will always be i.i.d draws from the same distribution as the
reference rater labels.</p></li>
<li><p><strong>k_other_raters_per_label=1</strong> -- The number of other raters to generate labels for.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="surveyequivalence.synthetic_datasets.SyntheticBinaryDatasetGenerator.make_histogram">
<span class="sig-name descname"><span class="pre">make_histogram</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ax</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.synthetic_datasets.SyntheticBinaryDatasetGenerator.make_histogram" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ax</strong> -- A matplotlib Axes instance</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="surveyequivalence.synthetic_datasets.SyntheticBinaryDatasetGenerator.plot_item_state_distribution">
<span class="sig-name descname"><span class="pre">plot_item_state_distribution</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.synthetic_datasets.SyntheticBinaryDatasetGenerator.plot_item_state_distribution" title="Permalink to this definition">¶</a></dt>
<dd><p>called if you are making a standalone graph; for insets, .make_histogram is called directly</p>
</dd></dl>

</dd></dl>

</section>
<section id="dataset">
<h3>Dataset<a class="headerlink" href="#dataset" title="Permalink to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="surveyequivalence.synthetic_datasets.Dataset">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">surveyequivalence.synthetic_datasets.</span></span><span class="sig-name descname"><span class="pre">Dataset</span></span><a class="headerlink" href="#surveyequivalence.synthetic_datasets.Dataset" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>A Dataset</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="surveyequivalence.synthetic_datasets.SyntheticDataset">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">surveyequivalence.synthetic_datasets.</span></span><span class="sig-name descname"><span class="pre">SyntheticDataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ds_generator</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#surveyequivalence.synthetic_datasets.SyntheticBinaryDatasetGenerator" title="surveyequivalence.synthetic_datasets.SyntheticBinaryDatasetGenerator"><span class="pre">SyntheticBinaryDatasetGenerator</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">mock_version</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">argv</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.synthetic_datasets.SyntheticDataset" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#surveyequivalence.synthetic_datasets.Dataset" title="surveyequivalence.synthetic_datasets.Dataset"><code class="xref py py-class docutils literal notranslate"><span class="pre">Dataset</span></code></a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ds_generator</strong> -- </p></li>
<li><p><strong>attributes</strong> (<em>Sets all the</em>) -- </p></li>
<li><p><strong>SyntheticBinaryDatasetGenerator</strong> (<em>by running the</em>) -- </p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="surveyequivalence.synthetic_datasets.SyntheticDataset.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dirname</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'running_example'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.synthetic_datasets.SyntheticDataset.save" title="Permalink to this definition">¶</a></dt>
<dd><p>Save ratings and predictions to csv files</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dirname</strong> -- A subdirectory name in which to store saved results</p></li>
<li><p><strong>include_timestamp_in_dirname</strong> -- Whether to postpend directory name with current timestamp</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="surveyequivalence.synthetic_datasets.make_running_example_dataset">
<span class="sig-prename descclassname"><span class="pre">surveyequivalence.synthetic_datasets.</span></span><span class="sig-name descname"><span class="pre">make_running_example_dataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_items_per_dataset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_labels_per_item</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">minimal</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include_hard_classifier</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include_soft_classifier</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#surveyequivalence.synthetic_datasets.SyntheticDataset" title="surveyequivalence.synthetic_datasets.SyntheticDataset"><span class="pre">SyntheticDataset</span></a></span></span><a class="headerlink" href="#surveyequivalence.synthetic_datasets.make_running_example_dataset" title="Permalink to this definition">¶</a></dt>
<dd><p>This generates the running example dataset used in the original Survey Equivalence paper.</p>
<p>Three states: 70% high = 80/20, 10% med = 50/50; 20% low = 10/90</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_items_per_dataset</strong> -- </p></li>
<li><p><strong>num_labels_per_item</strong> -- </p></li>
<li><p><strong>minimal</strong> -- If minimal, use FixedStateGenerator, which generates labels in exact proportion to probabilities specified         in the state, rather than each label being an iid draw from the State.</p></li>
<li><p><strong>include_hard_classifier</strong> -- Includes a hard classifier which draws labels 90/10 for high state; 50/50 for medium; 05/95 fow low state</p></li>
<li><p><strong>include_soft_classifier</strong> -- Includes a soft classifier which runs the hard_classifier to generate a label and then maps it to a calibrated         prediction (.7681 when the label is positive; .3226 when the label is negative). Also includes an ideal         classifier that always predicts the probability given by the State of the item.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">SurveyEquivalence</a></h1>








<h3>Navigation</h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="getting_started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorials.html">Tutorials</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">API</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#equivalence-module">Equivalence Module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#analysispipeline">AnalysisPipeline</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#surveyequivalence.equivalence.AnalysisPipeline"><code class="docutils literal notranslate"><span class="pre">AnalysisPipeline</span></code></a><ul>
<li class="toctree-l5"><a class="reference internal" href="#surveyequivalence.equivalence.AnalysisPipeline.output_csv"><code class="docutils literal notranslate"><span class="pre">AnalysisPipeline.output_csv()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#surveyequivalence.equivalence.AnalysisPipeline.path_for_saving"><code class="docutils literal notranslate"><span class="pre">AnalysisPipeline.path_for_saving()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#surveyequivalence.equivalence.AnalysisPipeline.run"><code class="docutils literal notranslate"><span class="pre">AnalysisPipeline.run()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#surveyequivalence.equivalence.AnalysisPipeline.save"><code class="docutils literal notranslate"><span class="pre">AnalysisPipeline.save()</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="#surveyequivalence.equivalence.load_saved_pipeline"><code class="docutils literal notranslate"><span class="pre">load_saved_pipeline()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#plot">Plot</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#surveyequivalence.equivalence.Plot"><code class="docutils literal notranslate"><span class="pre">Plot</span></code></a><ul>
<li class="toctree-l5"><a class="reference internal" href="#surveyequivalence.equivalence.Plot.plot"><code class="docutils literal notranslate"><span class="pre">Plot.plot()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#surveyequivalence.equivalence.Plot.save"><code class="docutils literal notranslate"><span class="pre">Plot.save()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#equivalences">Equivalences</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#surveyequivalence.equivalence.Equivalences"><code class="docutils literal notranslate"><span class="pre">Equivalences</span></code></a><ul>
<li class="toctree-l5"><a class="reference internal" href="#surveyequivalence.equivalence.Equivalences.lower_bounds"><code class="docutils literal notranslate"><span class="pre">Equivalences.lower_bounds</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#surveyequivalence.equivalence.Equivalences.upper_bounds"><code class="docutils literal notranslate"><span class="pre">Equivalences.upper_bounds</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#classifierresults">ClassifierResults</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#surveyequivalence.equivalence.ClassifierResults"><code class="docutils literal notranslate"><span class="pre">ClassifierResults</span></code></a><ul>
<li class="toctree-l5"><a class="reference internal" href="#surveyequivalence.equivalence.ClassifierResults.lower_bounds"><code class="docutils literal notranslate"><span class="pre">ClassifierResults.lower_bounds</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#surveyequivalence.equivalence.ClassifierResults.upper_bounds"><code class="docutils literal notranslate"><span class="pre">ClassifierResults.upper_bounds</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#surveyequivalence.equivalence.ClassifierResults.values"><code class="docutils literal notranslate"><span class="pre">ClassifierResults.values</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#powercurve">PowerCurve</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#surveyequivalence.equivalence.PowerCurve"><code class="docutils literal notranslate"><span class="pre">PowerCurve</span></code></a><ul>
<li class="toctree-l5"><a class="reference internal" href="#surveyequivalence.equivalence.PowerCurve.compute_equivalence_at_actuals"><code class="docutils literal notranslate"><span class="pre">PowerCurve.compute_equivalence_at_actuals()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#surveyequivalence.equivalence.PowerCurve.compute_equivalence_at_mean"><code class="docutils literal notranslate"><span class="pre">PowerCurve.compute_equivalence_at_mean()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#surveyequivalence.equivalence.PowerCurve.compute_equivalences"><code class="docutils literal notranslate"><span class="pre">PowerCurve.compute_equivalences()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#surveyequivalence.equivalence.PowerCurve.reliability_of_beating_classifier"><code class="docutils literal notranslate"><span class="pre">PowerCurve.reliability_of_beating_classifier()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#surveyequivalence.equivalence.PowerCurve.reliability_of_difference"><code class="docutils literal notranslate"><span class="pre">PowerCurve.reliability_of_difference()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-surveyequivalence.combiners">Combiners</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#surveyequivalence.combiners.AnonymousBayesianCombiner"><code class="docutils literal notranslate"><span class="pre">AnonymousBayesianCombiner</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#surveyequivalence.combiners.AnonymousBayesianCombiner.combine"><code class="docutils literal notranslate"><span class="pre">AnonymousBayesianCombiner.combine()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#surveyequivalence.combiners.AnonymousBayesianCombiner.labelSeqProb"><code class="docutils literal notranslate"><span class="pre">AnonymousBayesianCombiner.labelSeqProb()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#surveyequivalence.combiners.AnonymousBayesianCombiner.probabilityOneItem"><code class="docutils literal notranslate"><span class="pre">AnonymousBayesianCombiner.probabilityOneItem()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#surveyequivalence.combiners.AnonymousBayesianCombiner.sumOfProbabilities"><code class="docutils literal notranslate"><span class="pre">AnonymousBayesianCombiner.sumOfProbabilities()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#surveyequivalence.combiners.Combiner"><code class="docutils literal notranslate"><span class="pre">Combiner</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#surveyequivalence.combiners.Combiner.combine"><code class="docutils literal notranslate"><span class="pre">Combiner.combine()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#surveyequivalence.combiners.DiscreteDistributionPrediction"><code class="docutils literal notranslate"><span class="pre">DiscreteDistributionPrediction</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#surveyequivalence.combiners.DiscreteDistributionPrediction.draw_discrete_label"><code class="docutils literal notranslate"><span class="pre">DiscreteDistributionPrediction.draw_discrete_label()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#surveyequivalence.combiners.DiscreteDistributionPrediction.label_probability"><code class="docutils literal notranslate"><span class="pre">DiscreteDistributionPrediction.label_probability()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#surveyequivalence.combiners.DiscreteDistributionPrediction.value"><code class="docutils literal notranslate"><span class="pre">DiscreteDistributionPrediction.value</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#surveyequivalence.combiners.DiscreteDistributionPrediction.value_prob"><code class="docutils literal notranslate"><span class="pre">DiscreteDistributionPrediction.value_prob</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#surveyequivalence.combiners.DiscretePrediction"><code class="docutils literal notranslate"><span class="pre">DiscretePrediction</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#surveyequivalence.combiners.DiscretePrediction.value"><code class="docutils literal notranslate"><span class="pre">DiscretePrediction.value</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#surveyequivalence.combiners.FrequencyCombiner"><code class="docutils literal notranslate"><span class="pre">FrequencyCombiner</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#surveyequivalence.combiners.FrequencyCombiner.combine"><code class="docutils literal notranslate"><span class="pre">FrequencyCombiner.combine()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#surveyequivalence.combiners.MeanCombiner"><code class="docutils literal notranslate"><span class="pre">MeanCombiner</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#surveyequivalence.combiners.MeanCombiner.combine"><code class="docutils literal notranslate"><span class="pre">MeanCombiner.combine()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#surveyequivalence.combiners.NumericPrediction"><code class="docutils literal notranslate"><span class="pre">NumericPrediction</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#surveyequivalence.combiners.NumericPrediction.value"><code class="docutils literal notranslate"><span class="pre">NumericPrediction.value</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#surveyequivalence.combiners.PluralityVote"><code class="docutils literal notranslate"><span class="pre">PluralityVote</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#surveyequivalence.combiners.PluralityVote.combine"><code class="docutils literal notranslate"><span class="pre">PluralityVote.combine()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#surveyequivalence.combiners.Prediction"><code class="docutils literal notranslate"><span class="pre">Prediction</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#surveyequivalence.combiners.Prediction.value"><code class="docutils literal notranslate"><span class="pre">Prediction.value</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-surveyequivalence.scoring_functions">Scoring Functions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#surveyequivalence.scoring_functions.AUCScore"><code class="docutils literal notranslate"><span class="pre">AUCScore</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#surveyequivalence.scoring_functions.AUCScore.score"><code class="docutils literal notranslate"><span class="pre">AUCScore.score()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#surveyequivalence.scoring_functions.AgreementScore"><code class="docutils literal notranslate"><span class="pre">AgreementScore</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#surveyequivalence.scoring_functions.AgreementScore.expected_score_anonymous_raters"><code class="docutils literal notranslate"><span class="pre">AgreementScore.expected_score_anonymous_raters()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#surveyequivalence.scoring_functions.AgreementScore.score"><code class="docutils literal notranslate"><span class="pre">AgreementScore.score()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#surveyequivalence.scoring_functions.Correlation"><code class="docutils literal notranslate"><span class="pre">Correlation</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#surveyequivalence.scoring_functions.Correlation.score"><code class="docutils literal notranslate"><span class="pre">Correlation.score()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#surveyequivalence.scoring_functions.CrossEntropyScore"><code class="docutils literal notranslate"><span class="pre">CrossEntropyScore</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#surveyequivalence.scoring_functions.CrossEntropyScore.expected_score_anonymous_raters"><code class="docutils literal notranslate"><span class="pre">CrossEntropyScore.expected_score_anonymous_raters()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#surveyequivalence.scoring_functions.CrossEntropyScore.score"><code class="docutils literal notranslate"><span class="pre">CrossEntropyScore.score()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#surveyequivalence.scoring_functions.DMIScore_for_Hard_Classifier"><code class="docutils literal notranslate"><span class="pre">DMIScore_for_Hard_Classifier</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#surveyequivalence.scoring_functions.DMIScore_for_Hard_Classifier.expected_score_anonymous_raters"><code class="docutils literal notranslate"><span class="pre">DMIScore_for_Hard_Classifier.expected_score_anonymous_raters()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#surveyequivalence.scoring_functions.DMIScore_for_Hard_Classifier.score"><code class="docutils literal notranslate"><span class="pre">DMIScore_for_Hard_Classifier.score()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#surveyequivalence.scoring_functions.DMIScore_for_Soft_Classifier"><code class="docutils literal notranslate"><span class="pre">DMIScore_for_Soft_Classifier</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#surveyequivalence.scoring_functions.DMIScore_for_Soft_Classifier.expected_score_anonymous_raters"><code class="docutils literal notranslate"><span class="pre">DMIScore_for_Soft_Classifier.expected_score_anonymous_raters()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#surveyequivalence.scoring_functions.DMIScore_for_Soft_Classifier.score"><code class="docutils literal notranslate"><span class="pre">DMIScore_for_Soft_Classifier.score()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#surveyequivalence.scoring_functions.F1Score"><code class="docutils literal notranslate"><span class="pre">F1Score</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#surveyequivalence.scoring_functions.F1Score.score"><code class="docutils literal notranslate"><span class="pre">F1Score.score()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#surveyequivalence.scoring_functions.PrecisionScore"><code class="docutils literal notranslate"><span class="pre">PrecisionScore</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#surveyequivalence.scoring_functions.PrecisionScore.expected_score_anonymous_raters"><code class="docutils literal notranslate"><span class="pre">PrecisionScore.expected_score_anonymous_raters()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#surveyequivalence.scoring_functions.PrecisionScore.score"><code class="docutils literal notranslate"><span class="pre">PrecisionScore.score()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#surveyequivalence.scoring_functions.RecallScore"><code class="docutils literal notranslate"><span class="pre">RecallScore</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#surveyequivalence.scoring_functions.RecallScore.score"><code class="docutils literal notranslate"><span class="pre">RecallScore.score()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#surveyequivalence.scoring_functions.Scorer"><code class="docutils literal notranslate"><span class="pre">Scorer</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#surveyequivalence.scoring_functions.Scorer.expected_score"><code class="docutils literal notranslate"><span class="pre">Scorer.expected_score()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#surveyequivalence.scoring_functions.Scorer.expected_score_anonymous_raters"><code class="docutils literal notranslate"><span class="pre">Scorer.expected_score_anonymous_raters()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#surveyequivalence.scoring_functions.Scorer.expected_score_non_anonymous_raters"><code class="docutils literal notranslate"><span class="pre">Scorer.expected_score_non_anonymous_raters()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#surveyequivalence.scoring_functions.Scorer.score"><code class="docutils literal notranslate"><span class="pre">Scorer.score()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#surveyequivalence.scoring_functions.Scorer_for_Hard_Classifier"><code class="docutils literal notranslate"><span class="pre">Scorer_for_Hard_Classifier</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#surveyequivalence.scoring_functions.Scorer_for_Hard_Classifier.expected_score"><code class="docutils literal notranslate"><span class="pre">Scorer_for_Hard_Classifier.expected_score()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#surveyequivalence.scoring_functions.Scorer_for_Hard_Classifier.expected_score_anonymous_raters"><code class="docutils literal notranslate"><span class="pre">Scorer_for_Hard_Classifier.expected_score_anonymous_raters()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#surveyequivalence.scoring_functions.Scorer_for_Hard_Classifier.expected_score_non_anonymous_raters"><code class="docutils literal notranslate"><span class="pre">Scorer_for_Hard_Classifier.expected_score_non_anonymous_raters()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#surveyequivalence.scoring_functions.Scorer_for_Hard_Classifier.score"><code class="docutils literal notranslate"><span class="pre">Scorer_for_Hard_Classifier.score()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#surveyequivalence.scoring_functions.Scorer_for_Numeric_Classifier"><code class="docutils literal notranslate"><span class="pre">Scorer_for_Numeric_Classifier</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#surveyequivalence.scoring_functions.Scorer_for_Numeric_Classifier.expected_score"><code class="docutils literal notranslate"><span class="pre">Scorer_for_Numeric_Classifier.expected_score()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#surveyequivalence.scoring_functions.Scorer_for_Numeric_Classifier.expected_score_anonymous_raters"><code class="docutils literal notranslate"><span class="pre">Scorer_for_Numeric_Classifier.expected_score_anonymous_raters()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#surveyequivalence.scoring_functions.Scorer_for_Numeric_Classifier.expected_score_non_anonymous_raters"><code class="docutils literal notranslate"><span class="pre">Scorer_for_Numeric_Classifier.expected_score_non_anonymous_raters()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#surveyequivalence.scoring_functions.Scorer_for_Numeric_Classifier.score"><code class="docutils literal notranslate"><span class="pre">Scorer_for_Numeric_Classifier.score()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#surveyequivalence.scoring_functions.Scorer_for_Soft_Classifier"><code class="docutils literal notranslate"><span class="pre">Scorer_for_Soft_Classifier</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#surveyequivalence.scoring_functions.Scorer_for_Soft_Classifier.expected_score"><code class="docutils literal notranslate"><span class="pre">Scorer_for_Soft_Classifier.expected_score()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#surveyequivalence.scoring_functions.Scorer_for_Soft_Classifier.expected_score_anonymous_raters"><code class="docutils literal notranslate"><span class="pre">Scorer_for_Soft_Classifier.expected_score_anonymous_raters()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#surveyequivalence.scoring_functions.Scorer_for_Soft_Classifier.expected_score_non_anonymous_raters"><code class="docutils literal notranslate"><span class="pre">Scorer_for_Soft_Classifier.expected_score_non_anonymous_raters()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#surveyequivalence.scoring_functions.Scorer_for_Soft_Classifier.score"><code class="docutils literal notranslate"><span class="pre">Scorer_for_Soft_Classifier.score()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#surveyequivalence.scoring_functions.comb"><code class="docutils literal notranslate"><span class="pre">comb()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#surveyequivalence.scoring_functions.frac"><code class="docutils literal notranslate"><span class="pre">frac()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#surveyequivalence.scoring_functions.mode"><code class="docutils literal notranslate"><span class="pre">mode()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#synthetic-dataset-generation">Synthetic Dataset Generation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#states">States</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#surveyequivalence.synthetic_datasets.DiscreteState"><code class="docutils literal notranslate"><span class="pre">DiscreteState</span></code></a><ul>
<li class="toctree-l5"><a class="reference internal" href="#surveyequivalence.synthetic_datasets.DiscreteState.draw_labels"><code class="docutils literal notranslate"><span class="pre">DiscreteState.draw_labels()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#distributions-over-states">Distributions Over States</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#surveyequivalence.synthetic_datasets.DistributionOverStates"><code class="docutils literal notranslate"><span class="pre">DistributionOverStates</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#surveyequivalence.synthetic_datasets.DiscreteDistributionOverStates"><code class="docutils literal notranslate"><span class="pre">DiscreteDistributionOverStates</span></code></a><ul>
<li class="toctree-l5"><a class="reference internal" href="#surveyequivalence.synthetic_datasets.DiscreteDistributionOverStates.draw_states"><code class="docutils literal notranslate"><span class="pre">DiscreteDistributionOverStates.draw_states()</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="#surveyequivalence.synthetic_datasets.FixedStateGenerator"><code class="docutils literal notranslate"><span class="pre">FixedStateGenerator</span></code></a><ul>
<li class="toctree-l5"><a class="reference internal" href="#surveyequivalence.synthetic_datasets.FixedStateGenerator.draw_states"><code class="docutils literal notranslate"><span class="pre">FixedStateGenerator.draw_states()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#mock-classifiers">Mock Classifiers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#surveyequivalence.synthetic_datasets.MockClassifier"><code class="docutils literal notranslate"><span class="pre">MockClassifier</span></code></a><ul>
<li class="toctree-l5"><a class="reference internal" href="#surveyequivalence.synthetic_datasets.MockClassifier.make_predictions"><code class="docutils literal notranslate"><span class="pre">MockClassifier.make_predictions()</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="#surveyequivalence.synthetic_datasets.MappedDiscreteMockClassifier"><code class="docutils literal notranslate"><span class="pre">MappedDiscreteMockClassifier</span></code></a><ul>
<li class="toctree-l5"><a class="reference internal" href="#surveyequivalence.synthetic_datasets.MappedDiscreteMockClassifier.make_predictions"><code class="docutils literal notranslate"><span class="pre">MappedDiscreteMockClassifier.make_predictions()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#dataset-generators">Dataset Generators</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#surveyequivalence.synthetic_datasets.SyntheticDatasetGenerator"><code class="docutils literal notranslate"><span class="pre">SyntheticDatasetGenerator</span></code></a><ul>
<li class="toctree-l5"><a class="reference internal" href="#surveyequivalence.synthetic_datasets.SyntheticDatasetGenerator.generate_labels"><code class="docutils literal notranslate"><span class="pre">SyntheticDatasetGenerator.generate_labels()</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="#surveyequivalence.synthetic_datasets.SyntheticBinaryDatasetGenerator"><code class="docutils literal notranslate"><span class="pre">SyntheticBinaryDatasetGenerator</span></code></a><ul>
<li class="toctree-l5"><a class="reference internal" href="#surveyequivalence.synthetic_datasets.SyntheticBinaryDatasetGenerator.make_histogram"><code class="docutils literal notranslate"><span class="pre">SyntheticBinaryDatasetGenerator.make_histogram()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#surveyequivalence.synthetic_datasets.SyntheticBinaryDatasetGenerator.plot_item_state_distribution"><code class="docutils literal notranslate"><span class="pre">SyntheticBinaryDatasetGenerator.plot_item_state_distribution()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#dataset">Dataset</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#surveyequivalence.synthetic_datasets.Dataset"><code class="docutils literal notranslate"><span class="pre">Dataset</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#surveyequivalence.synthetic_datasets.SyntheticDataset"><code class="docutils literal notranslate"><span class="pre">SyntheticDataset</span></code></a><ul>
<li class="toctree-l5"><a class="reference internal" href="#surveyequivalence.synthetic_datasets.SyntheticDataset.save"><code class="docutils literal notranslate"><span class="pre">SyntheticDataset.save()</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="#surveyequivalence.synthetic_datasets.make_running_example_dataset"><code class="docutils literal notranslate"><span class="pre">make_running_example_dataset()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
      <li>Previous: <a href="tutorials.html" title="previous chapter">Tutorials</a></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2021, Paul Resnick, Yuqing Kong, Grant Schoenebeck, Tim Weninger.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 6.1.3</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.13</a>
      
      |
      <a href="_sources/api.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>