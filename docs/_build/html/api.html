
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>API &#8212; SurveyEquivalence 1.0 documentation</title>
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="Tutorials" href="tutorials.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="section" id="api">
<h1>API<a class="headerlink" href="#api" title="Permalink to this headline">¶</a></h1>
<div class="section" id="equivalence-module">
<h2>Equivalence Module<a class="headerlink" href="#equivalence-module" title="Permalink to this headline">¶</a></h2>
<div class="section" id="analysispipeline">
<h3>AnalysisPipeline<a class="headerlink" href="#analysispipeline" title="Permalink to this headline">¶</a></h3>
<dl class="py class">
<dt id="surveyequivalence.equivalence.AnalysisPipeline">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">surveyequivalence.equivalence.</span></code><code class="sig-name descname"><span class="pre">AnalysisPipeline</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">W</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">pandas.core.frame.DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sparse_experts</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">expert_cols</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">amateur_cols</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">classifier_predictions</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">pandas.core.frame.DataFrame</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">combiner</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#surveyequivalence.combiners.Combiner" title="surveyequivalence.combiners.Combiner"><span class="pre">surveyequivalence.combiners.Combiner</span></a><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scorer</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#surveyequivalence.scoring_functions.Scorer" title="surveyequivalence.scoring_functions.Scorer"><span class="pre">surveyequivalence.scoring_functions.Scorer</span></a><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">allowable_labels</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_k</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_bootstrap_item_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_rater_subsets</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">200</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_K</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ratersets_memo</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">predictions_memo</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">item_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbosity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">run_on_creation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">procs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">7</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.equivalence.AnalysisPipeline" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>The main class for running an analysis</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>W</strong> (<em>pd.DataFrame</em>) -- The ratings dataframe with one column for each rater, one row for each item</p></li>
<li><p><strong>sparse_experts</strong> (<em>bool</em>) -- True (default) if some raters may not have rated all items</p></li>
<li><p><strong>expert_cols</strong> (<em>Sequence</em><em>[</em><em>str</em><em>] </em><em>=</em><em> [</em><em>]</em>) -- A list of column names, one for each potential &quot;reference rater&quot; whose the classifier is trying to         predict. These are also the columns used for computing the power curve for survey equivalence</p></li>
<li><p><strong>amateur_cols</strong> (<em>Sequence</em><em>[</em><em>str</em><em>] </em><em>=</em><em> [</em><em>]</em>) -- A list of column names, one for each potential &quot;other rater&quot;. Their ratings are not used for evaluating         the classifier, but a separate power curve may be computed for them, using surveys of k of them         to predict a reference rater's label. Survey equivalences can also be calculated between j &quot;other raters&quot;         and k reference raters.</p></li>
<li><p><strong>classifier_predictions</strong> (<em>pd.DataFrame = None</em>) -- A dataframe with one column for each classifier for which we want to compute survey equivalences.         One row for each item; row indexes should be the same as for W</p></li>
<li><p><strong>combiner</strong> (<em>Combiner = None</em>) -- A combiner that is used to make a prediction about the next label for an item,         given labels from some other raters.</p></li>
<li><p><strong>scorer</strong> (<em>Scorer = None</em>) -- A scorer that takes a vector of predictions and a vector of realized reference rater labels and         yields a numeric score.</p></li>
<li><p><strong>allowable_labels</strong> (<em>Sequence</em><em>[</em><em>str</em><em>] </em><em>= None</em>) -- A list of the potential label strings that a rater is permitted to assign to an item</p></li>
<li><p><strong>min_k=0</strong> -- When computing power curves, the smallest survey size to include</p></li>
<li><p><strong>num_bootstrap_item_samples=100</strong> -- When computing error bars, how many bootstrap samples of items to create</p></li>
<li><p><strong>max_rater_subsets=200</strong> -- When computing power curves, we compute the average score over predictions made from many subsets         of reference raters of size k. When k is small, we choose all subsets of size k. For larger k,         we take a sample from the powerset. This parameters determines how many subsets to select.</p></li>
<li><p><strong>max_K=10</strong> -- When computing computing curves, the largest survey size to include. Cannot be larger than         the number of reference raters in W, minus one.</p></li>
<li><p><strong>ratersets_memo=None</strong> -- While running, a dictionary is create to memoize certain computations, for efficiency. A value         be passed in in order to reuse the memoized computations from a previous run.</p></li>
<li><p><strong>predictions_memo=None</strong> -- While running, a dictionary is create to memoize certain computations, for efficiency. A value         be passed in in order to reuse the memoized computations from a previous run.</p></li>
<li><p><strong>item_samples=None</strong> -- If specified, the set of bootstrap item samples to use for computing error bars.         If not specified, a new set of bootstrap item samples will be created.</p></li>
<li><p><strong>verbosity=1</strong> -- Controls how much information is printed to the console during execution. Set a higher number         to help with debugging.</p></li>
<li><p><strong>= True</strong> (<em>run_on_creation</em>) -- Whether to actually run the analysis pipeline</p></li>
<li><p><strong>- 1</strong> (<em>procs=pathos.helpers.cpu_count</em><em>(</em><em>)</em>) -- How many processors are available for parallel execution</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="surveyequivalence.equivalence.AnalysisPipeline.output_csv">
<code class="sig-name descname"><span class="pre">output_csv</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fname</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.equivalence.AnalysisPipeline.output_csv" title="Permalink to this definition">¶</a></dt>
<dd><p>output the dataframe and the expert predictions</p>
</dd></dl>

<dl class="py method">
<dt id="surveyequivalence.equivalence.AnalysisPipeline.path_for_saving">
<code class="sig-name descname"><span class="pre">path_for_saving</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dirname_base</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'analysis_pipeline'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include_timestamp</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">root_dir</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'C:\\Users\\tweni\\PycharmProjects\\surveyequivalence'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.equivalence.AnalysisPipeline.path_for_saving" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dirname_base</strong> -- A name that describes the analysis; / will be treated as a subdirectory</p></li>
<li><p><strong>include_timestamp</strong> -- Whether to make a folder indicating the timestamp at which the run was done.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><em>A path of the form {ROOT_DIR}/{self.run_timestamp}/{dirname_base}</em></p></li>
<li><p><em>If the path does not exist yet, it is created.</em></p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="surveyequivalence.equivalence.AnalysisPipeline.run">
<code class="sig-name descname"><span class="pre">run</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.equivalence.AnalysisPipeline.run" title="Permalink to this definition">¶</a></dt>
<dd><p>Create the power curve(s); normally invoked during __init__ but can be called separately.</p>
</dd></dl>

<dl class="py method">
<dt id="surveyequivalence.equivalence.AnalysisPipeline.save">
<code class="sig-name descname"><span class="pre">save</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">msg</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_results</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.equivalence.AnalysisPipeline.save" title="Permalink to this definition">¶</a></dt>
<dd><p>Save instance and results to files</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dirname_base=&quot;analysis_pipeline&quot;</strong> -- A subdirectory name in which to store saved results</p></li>
<li><p><strong>msg</strong> -- A text string to write in a README file that is generated</p></li>
<li><p><strong>save_results=True</strong> -- If True, generates a <cite>results_summary.txt</cite> file with power curve and survey equivalence summary stats</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="surveyequivalence.equivalence.load_saved_pipeline">
<code class="sig-prename descclassname"><span class="pre">surveyequivalence.equivalence.</span></code><code class="sig-name descname"><span class="pre">load_saved_pipeline</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.equivalence.load_saved_pipeline" title="Permalink to this definition">¶</a></dt>
<dd><p>Loads dataset, predictions, classifiers scores, and power curve(s) previously saved using     <a class="reference internal" href="#surveyequivalence.equivalence.AnalysisPipeline.save" title="surveyequivalence.equivalence.AnalysisPipeline.save"><code class="xref py py-meth docutils literal notranslate"><span class="pre">surveyequivalence.equivalence.AnalysisPipeline.save()</span></code></a></p>
</dd></dl>

</div>
<div class="section" id="plot">
<h3>Plot<a class="headerlink" href="#plot" title="Permalink to this headline">¶</a></h3>
<dl class="py class">
<dt id="surveyequivalence.equivalence.Plot">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">surveyequivalence.equivalence.</span></code><code class="sig-name descname"><span class="pre">Plot</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ax</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">expert_power_curve</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">amateur_power_curve</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">classifier_scores</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">color_map</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{'amateur_power_curve':</span> <span class="pre">'blue',</span> <span class="pre">'classifier':</span> <span class="pre">'green',</span> <span class="pre">'expert_power_curve':</span> <span class="pre">'black'}</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_axis_label</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'Agreement</span> <span class="pre">with</span> <span class="pre">reference</span> <span class="pre">rater'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">center_on</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'powercurve'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">legend_label</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'Expert</span> <span class="pre">raters'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">amateur_legend_label</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'Lay</span> <span class="pre">raters'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbosity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">generate_pgf</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.equivalence.Plot" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Generates visual display of power curve(s) and classifier scores, as matplotlib objects and as pgf for embedding in latex.     First run AnalysisPipeline to generate the PowerCurve and ClassifierResults objects to pass in to constructor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ax</strong> (<em>matplotlib.axes.Axes</em>) -- </p></li>
<li><p><strong>expert_power_curve</strong> (<a class="reference internal" href="#surveyequivalence.equivalence.PowerCurve" title="surveyequivalence.equivalence.PowerCurve"><em>PowerCurve</em></a>) -- a PowerCurve with scores for combinations of k reference raters in predicting a held-out reference rater</p></li>
<li><p><strong>amateur_power_curve=None</strong> (<a class="reference internal" href="#surveyequivalence.equivalence.PowerCurve" title="surveyequivalence.equivalence.PowerCurve"><em>PowerCurve</em></a>) -- a PowerCurve with scores for combinations of k other raters in predicting a held-out reference rater</p></li>
<li><p><strong>classifier_scores=None</strong> (<a class="reference internal" href="#surveyequivalence.equivalence.ClassifierResults" title="surveyequivalence.equivalence.ClassifierResults"><em>ClassifierResults</em></a>) -- </p></li>
<li><p><strong>color_map={'expert_power_curve'</strong> (<em>'black'</em><em>, </em><em>'amateur_power_curve': 'blue'</em><em>, </em><em>'classifier': 'green'}</em>) -- a dictionary specifying colors to use for the different elements of the graph to be pltoted</p></li>
<li><p><strong>with reference rater'</strong> (<em>y_axis_label='Agreement</em>) -- </p></li>
<li><p><strong>center_on=None</strong> (<em>float</em>) -- If a value is provided, it will be subtracted from all scores for classifiers and power curve values</p></li>
<li><p><strong>y_range=None</strong> -- If specified, a tuple of two values, the min and max y-values for the graph</p></li>
<li><p><strong>name='powercurve'</strong> -- A name for the plot</p></li>
<li><p><strong>raters'</strong> (<em>legend_label='Expert</em>) -- Legend label for the power curve for reference raters</p></li>
<li><p><strong>raters&quot;</strong> (<em>amateur_legend_label=&quot;Lay</em>) -- Legend label for the power curve for other raters</p></li>
<li><p><strong>verbosity=1</strong> -- Controls how much information is printed to the console during execution. Set a higher number         to help with debugging.</p></li>
<li><p><strong>generate_pgf=False</strong> -- If True, also populate data to enable create of pgf format, suitable for inclusion in latex         after calling <cite>.plot()</cite>, run         <cite>self.template.substitute(**self.template_dict)</cite></p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="surveyequivalence.equivalence.Plot.plot">
<code class="sig-name descname"><span class="pre">plot</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">include_expert_points</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'all'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">connect_expert_points</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include_classifiers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include_classifier_equivalences</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include_classifier_amateur_equivalences</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">other_rater_equivalences_to_include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include_droplines</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include_amateur_curve</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include_classifier_cis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include_seq_cis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x_ticks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">legend_loc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.equivalence.Plot.plot" title="Permalink to this definition">¶</a></dt>
<dd><p>The method that fills in the contents of the matplotlib Axes object</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include_expert_points='all'</strong> -- all means to plot all reference rater survey sizes on the x-axis of the power curve
Or include a list of numbers indicating which survey sizes to include</p></li>
<li><p><strong>connect_expert_points=True</strong> -- Whether to draw straight lines connecting the dots for survey power for surveys of successive sizes</p></li>
<li><p><strong>include_classifiers=True</strong> -- Whether to include horizontal lines showing the classifier score(s)</p></li>
<li><p><strong>include_classifier_equivalences=True</strong> -- Whether to include calculation of the equivalent number of reference raters for each classifier,             based on the intersection point of the classifier line and the reference raters' power curve</p></li>
<li><p><strong>include_classifier_amateur_equivalences=False</strong> -- Whether to include calculation of the equivalent number of other raters for each classifier,             based on the intersection point of the classifier line and the other raters' power curve</p></li>
<li><p><strong>other_rater_equivalences_to_include=</strong><strong>[</strong><strong>]</strong> -- A list of survey sizes for non-reference raters.             For each one, compute the equivalent number of reference raters yielding the same score.</p></li>
<li><p><strong>include_droplines=True</strong> -- Whether to include vertical lines from the intersection points (survey equivalences) to the x-axis</p></li>
<li><p><strong>include_amateur_curve=True</strong> -- Whether to include a power curve for the other, non-reference raters</p></li>
<li><p><strong>include_classifier_cis=True</strong> -- Whether to include error bars around the classifier horizontal lines</p></li>
<li><p><strong>include_seq_cis=True</strong> -- Whether to include error bars around the survey equivalence values</p></li>
<li><p><strong>x_ticks=None</strong> -- If provided, a  list of x values for which tick marks should be shown.             If None, then it will be automatically calculated.</p></li>
<li><p><strong>legend_loc=None</strong> -- String indicating where to place the legend (uses default if None).             Options as documented for <a class="reference external" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.legend.html">matplotlib.axes.Axes.legend</a>.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="surveyequivalence.equivalence.Plot.save">
<code class="sig-name descname"><span class="pre">save</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="pre">path:</span> <span class="pre">str</span></em>, <em class="sig-param"><span class="pre">fig:</span> <span class="pre">&lt;module</span> <span class="pre">'matplotlib.figure'</span> <span class="pre">from</span> <span class="pre">'c:\\users\\tweni\\pycharmprojects\\surveyequivalence\\venv\\lib\\site-packages\\matplotlib\\figure.py'&gt;</span></em>, <em class="sig-param"><span class="pre">plotname='plot'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.equivalence.Plot.save" title="Permalink to this definition">¶</a></dt>
<dd><p>Wrapper for the matplotlib save_plot function. Saves all data to the ./plots directory as png and tex files.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fig</strong> (<em>matplotlib figure object to be saved</em>) -- </p></li>
<li><p><strong>name</strong> (<em>Name for the file</em>) -- </p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="equivalences">
<h3>Equivalences<a class="headerlink" href="#equivalences" title="Permalink to this headline">¶</a></h3>
<dl class="py class">
<dt id="surveyequivalence.equivalence.Equivalences">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">surveyequivalence.equivalence.</span></code><code class="sig-name descname"><span class="pre">Equivalences</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">df</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.equivalence.Equivalences" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Contains a dataframe with one row for each bootstrap sample of items and one column for each classifier.     Cell contains the survey equivalence value (equivalent number of reference raters whose combined ratings     yields the same score as the classifier).</p>
<dl class="py method">
<dt id="surveyequivalence.equivalence.Equivalences.lower_bounds">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">lower_bounds</span></code><a class="headerlink" href="#surveyequivalence.equivalence.Equivalences.lower_bounds" title="Permalink to this definition">¶</a></dt>
<dd><p>returns:
:rtype: A pandas Series with a lower bound on the survey equivalence for each classifier.         Compute based on interval covering 95% of the bootstrap samples of items, if there are more than 200 of them.         Otherwise compute based on two standard deviations of the scores on bootstrap samples.</p>
</dd></dl>

<dl class="py method">
<dt id="surveyequivalence.equivalence.Equivalences.upper_bounds">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">upper_bounds</span></code><a class="headerlink" href="#surveyequivalence.equivalence.Equivalences.upper_bounds" title="Permalink to this definition">¶</a></dt>
<dd><p>returns:
:rtype: A pandas Series with an upper bound on the survey equivalence for each classifier.         Compute based on interval covering 95% of the bootstrap samples of items, if there are more than 200 of them.         Otherwise compute based on two standard deviations of the scores on bootstrap samples.</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="classifierresults">
<h3>ClassifierResults<a class="headerlink" href="#classifierresults" title="Permalink to this headline">¶</a></h3>
<dl class="py class">
<dt id="surveyequivalence.equivalence.ClassifierResults">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">surveyequivalence.equivalence.</span></code><code class="sig-name descname"><span class="pre">ClassifierResults</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">runs</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">df</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.equivalence.ClassifierResults" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<dl class="py method">
<dt id="surveyequivalence.equivalence.ClassifierResults.lower_bounds">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">lower_bounds</span></code><a class="headerlink" href="#surveyequivalence.equivalence.ClassifierResults.lower_bounds" title="Permalink to this definition">¶</a></dt>
<dd><p>returns:
:rtype: A pandas Series with a lower bound on the survey equivalence for each classifier.         Compute based on interval covering 95% of the bootstrap samples of items, if there are more than 200 of them.         Otherwise compute based on two standard deviations of the scores on bootstrap samples.</p>
</dd></dl>

<dl class="py method">
<dt id="surveyequivalence.equivalence.ClassifierResults.upper_bounds">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">upper_bounds</span></code><a class="headerlink" href="#surveyequivalence.equivalence.ClassifierResults.upper_bounds" title="Permalink to this definition">¶</a></dt>
<dd><p>returns:
:rtype: A pandas Series with an upper bound on the survey equivalence for each classifier.         Compute based on interval covering 95% of the bootstrap samples of items, if there are more than 200 of them.         Otherwise compute based on two standard deviations of the scores on bootstrap samples.</p>
</dd></dl>

<dl class="py method">
<dt id="surveyequivalence.equivalence.ClassifierResults.values">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">values</span></code><a class="headerlink" href="#surveyequivalence.equivalence.ClassifierResults.values" title="Permalink to this definition">¶</a></dt>
<dd><p>returns:
:rtype: Series of classifier scores for the first row, the actual item set, omitting results for all bootstrap item sets.</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="powercurve">
<h3>PowerCurve<a class="headerlink" href="#powercurve" title="Permalink to this headline">¶</a></h3>
<dl class="py class">
<dt id="surveyequivalence.equivalence.PowerCurve">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">surveyequivalence.equivalence.</span></code><code class="sig-name descname"><span class="pre">PowerCurve</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">runs</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">df</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.equivalence.PowerCurve" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#surveyequivalence.equivalence.ClassifierResults" title="surveyequivalence.equivalence.ClassifierResults"><code class="xref py py-class docutils literal notranslate"><span class="pre">surveyequivalence.equivalence.ClassifierResults</span></code></a></p>
<p>A special case of ClassifierResults where there is one column for each integer value k,     representing the mean score, over many samples of k raters, of the predictions generated by     combining ratings from k raters, scored against a reference rater.</p>
<dl class="py method">
<dt id="surveyequivalence.equivalence.PowerCurve.compute_equivalence_at_actuals">
<code class="sig-name descname"><span class="pre">compute_equivalence_at_actuals</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">classifier_score</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.equivalence.PowerCurve.compute_equivalence_at_actuals" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the equivalence of the score of the classifier on the actual item sample         based on the survey power curve computed for the actual item sample</p>
</dd></dl>

<dl class="py method">
<dt id="surveyequivalence.equivalence.PowerCurve.compute_equivalence_at_mean">
<code class="sig-name descname"><span class="pre">compute_equivalence_at_mean</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">classifier_score</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.equivalence.PowerCurve.compute_equivalence_at_mean" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the equivalence of the mean score of the classifier across the bootstrap item samples         based on the mean survey power curve computed across the bootstrap item samples</p>
</dd></dl>

<dl class="py method">
<dt id="surveyequivalence.equivalence.PowerCurve.compute_equivalences">
<code class="sig-name descname"><span class="pre">compute_equivalences</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">other</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">columns</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.equivalence.PowerCurve.compute_equivalences" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>self</strong> -- </p></li>
<li><p><strong>other</strong> -- The classifier scores that are compared against this PowerCurve to find equivalences
may either be an instance of ClassifierResults or a PowerCurve. Must have same row             indexes as self, one for each item sample</p></li>
<li><p><strong>columns</strong> -- a subset of the column names from other.df; if not specified, use all of them</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>a df with one row for each bootstrap run, and columns as specified by the columns parameter             Each cell is a float, the survey equivalence value for that column from other.             That is, the x s.t. expected score with x raters from self == classifier_score from other.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="surveyequivalence.equivalence.PowerCurve.reliability_of_beating_classifier">
<code class="sig-name descname"><span class="pre">reliability_of_beating_classifier</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">other</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">other_col</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.equivalence.PowerCurve.reliability_of_beating_classifier" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>other</strong> -- the other ClassifierResults or PowerCurve</p></li>
<li><p><strong>self_col</strong> -- the survey size (column) for self</p></li>
<li><p><strong>other_col</strong> -- the survey size (column) for other to compare, with matching bootstrap samples as rows</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>fraction of bootstrap runs where self power higher than other power</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="surveyequivalence.equivalence.PowerCurve.reliability_of_difference">
<code class="sig-name descname"><span class="pre">reliability_of_difference</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">other</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.equivalence.PowerCurve.reliability_of_difference" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>other</strong> -- another PowerCurve</p></li>
<li><p><strong>k</strong> -- survey size</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>fraction of bootstrap runs where power&#64;k higher for self than other power curve</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
</div>
<div class="section" id="module-surveyequivalence.combiners">
<span id="combiners"></span><h2>Combiners<a class="headerlink" href="#module-surveyequivalence.combiners" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="surveyequivalence.combiners.AnonymousBayesianCombiner">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">surveyequivalence.combiners.</span></code><code class="sig-name descname"><span class="pre">AnonymousBayesianCombiner</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.combiners.AnonymousBayesianCombiner" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#surveyequivalence.combiners.Combiner" title="surveyequivalence.combiners.Combiner"><code class="xref py py-class docutils literal notranslate"><span class="pre">surveyequivalence.combiners.Combiner</span></code></a></p>
<p>Anonymous Bayesian Combiner Class</p>
<dl class="py method">
<dt id="surveyequivalence.combiners.AnonymousBayesianCombiner.D_k">
<em class="property"><span class="pre">static</span> </em><code class="sig-name descname"><span class="pre">D_k</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="pre">labels:</span> <span class="pre">numpy.array</span></em>, <em class="sig-param"><span class="pre">W:</span> <span class="pre">numpy.matrix</span></em>, <em class="sig-param"><span class="pre">allowable_labels:</span> <span class="pre">Sequence[str])</span> <span class="pre">-&gt;</span> <span class="pre">(&lt;class</span> <span class="pre">'float'&gt;</span></em>, <em class="sig-param"><span class="pre">&lt;class</span> <span class="pre">'int'&gt;</span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.combiners.AnonymousBayesianCombiner.D_k" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the joint distribution over k anonymous ratings</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>labels</strong> (<em>item labels from several raters</em>) -- </p></li>
<li><p><strong>W</strong> (<em>item and rating dataset</em>) -- </p></li>
<li><p><strong>allowable_labels</strong> (<em>The set of labels that can be entered by the raters.</em>) -- </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>joint distribution, and num_items</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="surveyequivalence.combiners.AnonymousBayesianCombiner.D_k_item_contribution">
<em class="property"><span class="pre">static</span> </em><code class="sig-name descname"><span class="pre">D_k_item_contribution</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="pre">labels:</span> <span class="pre">numpy.array</span></em>, <em class="sig-param"><span class="pre">item:</span> <span class="pre">numpy.array</span></em>, <em class="sig-param"><span class="pre">allowable_labels:</span> <span class="pre">Sequence[str])</span> <span class="pre">-&gt;</span> <span class="pre">(&lt;class</span> <span class="pre">'float'&gt;</span></em>, <em class="sig-param"><span class="pre">&lt;class</span> <span class="pre">'float'&gt;</span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.combiners.AnonymousBayesianCombiner.D_k_item_contribution" title="Permalink to this definition">¶</a></dt>
<dd><p>ProbabilityOfOneItem function in Algorithm 5. Computes the contribution of a single item to the combiner</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>labels</strong> (<em>item labels from several raters</em>) -- </p></li>
<li><p><strong>item</strong> (<em>The item under current consideration</em>) -- </p></li>
<li><p><strong>allowable_labels</strong> (<em>The set of labels that can be entered by the raters.</em>) -- </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>The contribution of this item.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="surveyequivalence.combiners.AnonymousBayesianCombiner.combine">
<code class="sig-name descname"><span class="pre">combine</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">allowable_labels</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">W</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">numpy.matrix</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">item_id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">to_predict_for</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> &#x2192; <a class="reference internal" href="#surveyequivalence.combiners.DiscreteDistributionPrediction" title="surveyequivalence.combiners.DiscreteDistributionPrediction"><span class="pre">surveyequivalence.combiners.DiscreteDistributionPrediction</span></a><a class="headerlink" href="#surveyequivalence.combiners.AnonymousBayesianCombiner.combine" title="Permalink to this definition">¶</a></dt>
<dd><p>Algorithm 6
Compute the anonymous bayesian combiner. Combines rater labels like frequency_combiner, but this uses the
information from the item/rating dataset W.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>allowable_labels</strong> (<em>the set of labels/ratings allowed</em>) -- </p></li>
<li><p><strong>labels</strong> (<em>the k ratings</em>) -- </p></li>
<li><p><strong>W</strong> (<em>item and rating dataset</em>) -- </p></li>
<li><p><strong>item_id</strong> (<em>item index in W</em>) -- </p></li>
<li><p><strong>to_predict_for</strong> (<em>not used currently</em>) -- </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Prediction based on anonymous bayesian combiner</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="surveyequivalence.combiners.Combiner">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">surveyequivalence.combiners.</span></code><code class="sig-name descname"><span class="pre">Combiner</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">allowable_labels</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbosity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.combiners.Combiner" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">abc.ABC</span></code></p>
<p>Abstract class defining a combiner.</p>
<p>A combiner selects a single label from a bag/multiset of labels (and possibly other information) according to some
function. For example, the PluralityCombiner accepts a bag of labels and returns the label that is most frequent.</p>
<dl class="py method">
<dt id="surveyequivalence.combiners.Combiner.combine">
<em class="property"><span class="pre">abstract</span> </em><code class="sig-name descname"><span class="pre">combine</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">allowable_labels</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">W</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">numpy.matrix</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">item_id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">to_predict_for</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> &#x2192; <a class="reference internal" href="#surveyequivalence.combiners.DiscreteDistributionPrediction" title="surveyequivalence.combiners.DiscreteDistributionPrediction"><span class="pre">surveyequivalence.combiners.DiscreteDistributionPrediction</span></a><a class="headerlink" href="#surveyequivalence.combiners.Combiner.combine" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="surveyequivalence.combiners.DiscreteDistributionPrediction">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">surveyequivalence.combiners.</span></code><code class="sig-name descname"><span class="pre">DiscreteDistributionPrediction</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">label_names</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">probabilities</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">extreme_cutoff</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.02</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.combiners.DiscreteDistributionPrediction" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#surveyequivalence.combiners.Prediction" title="surveyequivalence.combiners.Prediction"><code class="xref py py-class docutils literal notranslate"><span class="pre">surveyequivalence.combiners.Prediction</span></code></a></p>
<p>A discrete distribution prediction where labels are associated with probabilities. Value takes the label with the
highest probability.</p>
<dl class="py method">
<dt id="surveyequivalence.combiners.DiscreteDistributionPrediction.draw_discrete_label">
<code class="sig-name descname"><span class="pre">draw_discrete_label</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.combiners.DiscreteDistributionPrediction.draw_discrete_label" title="Permalink to this definition">¶</a></dt>
<dd><p>Return one of the labels, drawn according to the distribution</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>A label</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="surveyequivalence.combiners.DiscreteDistributionPrediction.label_probability">
<code class="sig-name descname"><span class="pre">label_probability</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">label</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.combiners.DiscreteDistributionPrediction.label_probability" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the probability associated with an input label</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>label</strong> (<em>label to query</em>) -- </p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Probability assicated with label.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="surveyequivalence.combiners.DiscreteDistributionPrediction.value">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">value</span></code><a class="headerlink" href="#surveyequivalence.combiners.DiscreteDistributionPrediction.value" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the single label that has the highest predicted probability.
Break ties by taking the first one</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">DiscreteDistributionPrediction</span><span class="p">([</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;c&#39;</span><span class="p">],</span> <span class="p">[</span><span class="o">.</span><span class="mi">3</span><span class="p">,</span> <span class="o">.</span><span class="mi">4</span><span class="p">,</span> <span class="o">.</span><span class="mi">3</span><span class="p">])</span><span class="o">.</span><span class="n">value</span>
<span class="go">&#39;b&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">DiscreteDistributionPrediction</span><span class="p">([</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;c&#39;</span><span class="p">],</span> <span class="p">[</span><span class="o">.</span><span class="mi">4</span><span class="p">,</span> <span class="o">.</span><span class="mi">4</span><span class="p">,</span> <span class="o">.</span><span class="mi">2</span><span class="p">])</span><span class="o">.</span><span class="n">value</span>
<span class="go">&#39;a&#39;</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>label with highest probability</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="surveyequivalence.combiners.DiscreteDistributionPrediction.value_prob">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">value_prob</span></code><a class="headerlink" href="#surveyequivalence.combiners.DiscreteDistributionPrediction.value_prob" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the probability of the majority class</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">DiscreteDistributionPrediction</span><span class="p">([</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;c&#39;</span><span class="p">],</span> <span class="p">[</span><span class="o">.</span><span class="mi">3</span><span class="p">,</span> <span class="o">.</span><span class="mi">4</span><span class="p">,</span> <span class="o">.</span><span class="mi">3</span><span class="p">])</span><span class="o">.</span><span class="n">value</span>
<span class="go">.4</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">DiscreteDistributionPrediction</span><span class="p">([</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;c&#39;</span><span class="p">],</span> <span class="p">[</span><span class="o">.</span><span class="mi">4</span><span class="p">,</span> <span class="o">.</span><span class="mi">4</span><span class="p">,</span> <span class="o">.</span><span class="mi">2</span><span class="p">])</span><span class="o">.</span><span class="n">value</span>
<span class="go">.4</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>highest probability</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="surveyequivalence.combiners.DiscretePrediction">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">surveyequivalence.combiners.</span></code><code class="sig-name descname"><span class="pre">DiscretePrediction</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">label</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.combiners.DiscretePrediction" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#surveyequivalence.combiners.Prediction" title="surveyequivalence.combiners.Prediction"><code class="xref py py-class docutils literal notranslate"><span class="pre">surveyequivalence.combiners.Prediction</span></code></a></p>
<p>A discrete prediction. value is defined as a label</p>
<dl class="py method">
<dt id="surveyequivalence.combiners.DiscretePrediction.value">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">value</span></code><a class="headerlink" href="#surveyequivalence.combiners.DiscretePrediction.value" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="surveyequivalence.combiners.FrequencyCombiner">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">surveyequivalence.combiners.</span></code><code class="sig-name descname"><span class="pre">FrequencyCombiner</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">allowable_labels</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbosity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.combiners.FrequencyCombiner" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#surveyequivalence.combiners.Combiner" title="surveyequivalence.combiners.Combiner"><code class="xref py py-class docutils literal notranslate"><span class="pre">surveyequivalence.combiners.Combiner</span></code></a></p>
<p>Returns a vector of frequencies for each label</p>
<dl class="py method">
<dt id="surveyequivalence.combiners.FrequencyCombiner.combine">
<code class="sig-name descname"><span class="pre">combine</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">allowable_labels</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">W</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">numpy.matrix</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">item_id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">to_predict_for</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> &#x2192; <a class="reference internal" href="#surveyequivalence.combiners.DiscreteDistributionPrediction" title="surveyequivalence.combiners.DiscreteDistributionPrediction"><span class="pre">surveyequivalence.combiners.DiscreteDistributionPrediction</span></a><a class="headerlink" href="#surveyequivalence.combiners.FrequencyCombiner.combine" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the frequency vector for labels</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">FrequencyCombiner</span><span class="p">()</span><span class="o">.</span><span class="n">combine</span><span class="p">([</span><span class="s1">&#39;pos&#39;</span><span class="p">,</span> <span class="s1">&#39;neg&#39;</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([(</span><span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;pos&#39;</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;neg&#39;</span><span class="p">),</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="s1">&#39;neg&#39;</span><span class="p">)]),</span> <span class="p">)</span><span class="o">.</span><span class="n">probabilities</span>
<span class="go">[0.3333333333333333, 0.6666666666666666]</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">FrequencyCombiner</span><span class="p">()</span><span class="o">.</span><span class="n">combine</span><span class="p">([</span><span class="s1">&#39;pos&#39;</span><span class="p">,</span> <span class="s1">&#39;neg&#39;</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([(</span><span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;neg&#39;</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;neg&#39;</span><span class="p">),</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="s1">&#39;neg&#39;</span><span class="p">)]))</span><span class="o">.</span><span class="n">probabilities</span>
<span class="go">[0.0, 1.0]</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>allowable_labels</strong> (<em>not used in this combiner</em>) -- </p></li>
<li><p><strong>labels</strong> (<em>nnumeric values from particular rater ids; rater ids are ignored</em>) -- </p></li>
<li><p><strong>W</strong> (<em>not used in this combiner</em>) -- </p></li>
<li><p><strong>item_id</strong> (<em>not used in this combiner</em>) -- </p></li>
<li><p><strong>to_predict_for</strong> (<em>not used in this combiner</em>) -- </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Frequency vector of labels</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="surveyequivalence.combiners.MeanCombiner">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">surveyequivalence.combiners.</span></code><code class="sig-name descname"><span class="pre">MeanCombiner</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">allowable_labels</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbosity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.combiners.MeanCombiner" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#surveyequivalence.combiners.Combiner" title="surveyequivalence.combiners.Combiner"><code class="xref py py-class docutils literal notranslate"><span class="pre">surveyequivalence.combiners.Combiner</span></code></a></p>
<p>Combiner that returns the mean of all the labels.</p>
<dl class="py method">
<dt id="surveyequivalence.combiners.MeanCombiner.combine">
<code class="sig-name descname"><span class="pre">combine</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">allowable_labels</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">W</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">numpy.matrix</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">item_id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">to_predict_for</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> &#x2192; <a class="reference internal" href="#surveyequivalence.combiners.NumericPrediction" title="surveyequivalence.combiners.NumericPrediction"><span class="pre">surveyequivalence.combiners.NumericPrediction</span></a><a class="headerlink" href="#surveyequivalence.combiners.MeanCombiner.combine" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the single label that is most frequent</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>allowable_labels</strong> (<em>not used in this combiner</em>) -- </p></li>
<li><p><strong>labels</strong> (<em>nnumeric values from particular rater ids; rater ids are ignored</em>) -- </p></li>
<li><p><strong>W</strong> (<em>not used in this combiner</em>) -- </p></li>
<li><p><strong>item_id</strong> (<em>not used in this combiner</em>) -- </p></li>
<li><p><strong>to_predict_for</strong> (<em>not used in this combiner</em>) -- </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>The mean of the labels</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="surveyequivalence.combiners.NumericPrediction">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">surveyequivalence.combiners.</span></code><code class="sig-name descname"><span class="pre">NumericPrediction</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.combiners.NumericPrediction" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#surveyequivalence.combiners.Prediction" title="surveyequivalence.combiners.Prediction"><code class="xref py py-class docutils literal notranslate"><span class="pre">surveyequivalence.combiners.Prediction</span></code></a></p>
<p>A numeric prediction. value is defined as a number</p>
<dl class="py method">
<dt id="surveyequivalence.combiners.NumericPrediction.value">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">value</span></code><a class="headerlink" href="#surveyequivalence.combiners.NumericPrediction.value" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="surveyequivalence.combiners.PluralityVote">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">surveyequivalence.combiners.</span></code><code class="sig-name descname"><span class="pre">PluralityVote</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">allowable_labels</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbosity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.combiners.PluralityVote" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#surveyequivalence.combiners.Combiner" title="surveyequivalence.combiners.Combiner"><code class="xref py py-class docutils literal notranslate"><span class="pre">surveyequivalence.combiners.Combiner</span></code></a></p>
<p>Combiner that returns the single label that is most frequent</p>
<dl class="py method">
<dt id="surveyequivalence.combiners.PluralityVote.combine">
<code class="sig-name descname"><span class="pre">combine</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">allowable_labels</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">W</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">numpy.matrix</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">item_id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">to_predict_for</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> &#x2192; <a class="reference internal" href="#surveyequivalence.combiners.NumericPrediction" title="surveyequivalence.combiners.NumericPrediction"><span class="pre">surveyequivalence.combiners.NumericPrediction</span></a><a class="headerlink" href="#surveyequivalence.combiners.PluralityVote.combine" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the single label that is most frequent</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>allowable_labels</strong> (<em>not used in this combiner</em>) -- </p></li>
<li><p><strong>labels</strong> (<em>numeric values from particular rater ids; rater ids are ignored</em>) -- </p></li>
<li><p><strong>W</strong> (<em>not used in this combiner</em>) -- </p></li>
<li><p><strong>item_id</strong> (<em>not used in this combiner</em>) -- </p></li>
<li><p><strong>to_predict_for</strong> (<em>not used in this combiner</em>) -- </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>The most common label</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="surveyequivalence.combiners.Prediction">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">surveyequivalence.combiners.</span></code><code class="sig-name descname"><span class="pre">Prediction</span></code><a class="headerlink" href="#surveyequivalence.combiners.Prediction" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">abc.ABC</span></code></p>
<p>Abstract class that defines a value for many types of Predictions</p>
<dl class="py method">
<dt id="surveyequivalence.combiners.Prediction.value">
<em class="property"><span class="pre">abstract</span> <span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">value</span></code><a class="headerlink" href="#surveyequivalence.combiners.Prediction.value" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="module-surveyequivalence.scoring_functions">
<span id="scoring-functions"></span><h2>Scoring Functions<a class="headerlink" href="#module-surveyequivalence.scoring_functions" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="surveyequivalence.scoring_functions.AUCScore">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">surveyequivalence.scoring_functions.</span></code><code class="sig-name descname"><span class="pre">AUCScore</span></code><a class="headerlink" href="#surveyequivalence.scoring_functions.AUCScore" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#surveyequivalence.scoring_functions.Scorer" title="surveyequivalence.scoring_functions.Scorer"><code class="xref py py-class docutils literal notranslate"><span class="pre">surveyequivalence.scoring_functions.Scorer</span></code></a></p>
<dl class="py method">
<dt id="surveyequivalence.scoring_functions.AUCScore.score">
<em class="property"><span class="pre">static</span> </em><code class="sig-name descname"><span class="pre">score</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">classifier_predictions</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#surveyequivalence.combiners.DiscreteDistributionPrediction" title="surveyequivalence.combiners.DiscreteDistributionPrediction"><span class="pre">surveyequivalence.combiners.DiscreteDistributionPrediction</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rater_labels</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbosity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">float</span><a class="headerlink" href="#surveyequivalence.scoring_functions.AUCScore.score" title="Permalink to this definition">¶</a></dt>
<dd><p>AUC score. This function uses sklearn's AUC function, but does not work in many cases with multiple labels.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>classifier_predictions</strong> (<em>numeric values</em>) -- </p></li>
<li><p><strong>rater_labels</strong> (<em>sequence of labels</em><em>, </em><em>which should be numeric values</em>) -- </p></li>
<li><p><strong>verbosity</strong> -- </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>AUC Score</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="surveyequivalence.scoring_functions.AgreementScore">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">surveyequivalence.scoring_functions.</span></code><code class="sig-name descname"><span class="pre">AgreementScore</span></code><a class="headerlink" href="#surveyequivalence.scoring_functions.AgreementScore" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#surveyequivalence.scoring_functions.Scorer" title="surveyequivalence.scoring_functions.Scorer"><code class="xref py py-class docutils literal notranslate"><span class="pre">surveyequivalence.scoring_functions.Scorer</span></code></a></p>
<p>Agreement Scorer</p>
<dl class="py method">
<dt id="surveyequivalence.scoring_functions.AgreementScore.score">
<em class="property"><span class="pre">static</span> </em><code class="sig-name descname"><span class="pre">score</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">classifier_predictions</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rater_labels</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbosity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.scoring_functions.AgreementScore.score" title="Permalink to this definition">¶</a></dt>
<dd><p>Agreement score measures the normalized number of times that the predictor matched the label. Akin to a typical
accuracy score.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>classifier_predictions</strong> (<em>numeric values</em>) -- </p></li>
<li><p><strong>rater_labels</strong> (<em>sequence of labels</em><em>, </em><em>which should be numeric values</em>) -- </p></li>
<li><p><strong>verbosity</strong> -- </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Agreement score</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="surveyequivalence.scoring_functions.Correlation">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">surveyequivalence.scoring_functions.</span></code><code class="sig-name descname"><span class="pre">Correlation</span></code><a class="headerlink" href="#surveyequivalence.scoring_functions.Correlation" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#surveyequivalence.scoring_functions.Scorer" title="surveyequivalence.scoring_functions.Scorer"><code class="xref py py-class docutils literal notranslate"><span class="pre">surveyequivalence.scoring_functions.Scorer</span></code></a></p>
<p>Computes the Pearson correlation coefficient.</p>
<dl class="py method">
<dt id="surveyequivalence.scoring_functions.Correlation.score">
<em class="property"><span class="pre">static</span> </em><code class="sig-name descname"><span class="pre">score</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">classifier_predictions</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#surveyequivalence.combiners.NumericPrediction" title="surveyequivalence.combiners.NumericPrediction"><span class="pre">surveyequivalence.combiners.NumericPrediction</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rater_labels</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbosity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.scoring_functions.Correlation.score" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>classifier_predictions</strong> (<em>numeric values</em>) -- </p></li>
<li><p><strong>rater_labels</strong> (<em>sequence of labels</em><em>, </em><em>which should be numeric values</em>) -- </p></li>
<li><p><strong>verbosity</strong> -- </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Pearson correlation coefficient</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="surveyequivalence.scoring_functions.CrossEntropyScore">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">surveyequivalence.scoring_functions.</span></code><code class="sig-name descname"><span class="pre">CrossEntropyScore</span></code><a class="headerlink" href="#surveyequivalence.scoring_functions.CrossEntropyScore" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#surveyequivalence.scoring_functions.Scorer" title="surveyequivalence.scoring_functions.Scorer"><code class="xref py py-class docutils literal notranslate"><span class="pre">surveyequivalence.scoring_functions.Scorer</span></code></a></p>
<p>Cross Entropy Scorer</p>
<dl class="py method">
<dt id="surveyequivalence.scoring_functions.CrossEntropyScore.score">
<em class="property"><span class="pre">static</span> </em><code class="sig-name descname"><span class="pre">score</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">classifier_predictions</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#surveyequivalence.combiners.DiscreteDistributionPrediction" title="surveyequivalence.combiners.DiscreteDistributionPrediction"><span class="pre">surveyequivalence.combiners.DiscreteDistributionPrediction</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rater_labels</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbosity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.scoring_functions.CrossEntropyScore.score" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculates the Cross Entropy of the two labels.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">CrossEntropyScore</span><span class="o">.</span><span class="n">score</span><span class="p">([</span><span class="n">DiscreteDistributionPrediction</span><span class="p">([</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">],</span> <span class="n">prs</span><span class="p">)</span> <span class="k">for</span> <span class="n">prs</span> <span class="ow">in</span> <span class="p">[[</span><span class="o">.</span><span class="mi">3</span><span class="p">,</span> <span class="o">.</span><span class="mi">7</span><span class="p">],</span> <span class="p">[</span><span class="o">.</span><span class="mi">4</span><span class="p">,</span> <span class="o">.</span><span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="o">.</span><span class="mi">6</span><span class="p">,</span> <span class="o">.</span><span class="mi">4</span><span class="p">]]],</span>  <span class="p">[</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">])</span>
<span class="go">0.594597099859</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">CrossEntropyScore</span><span class="o">.</span><span class="n">score</span><span class="p">([</span><span class="n">DiscreteDistributionPrediction</span><span class="p">([</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">],</span> <span class="n">prs</span><span class="p">)</span> <span class="k">for</span> <span class="n">prs</span> <span class="ow">in</span> <span class="p">[[</span><span class="o">.</span><span class="mi">3</span><span class="p">,</span> <span class="o">.</span><span class="mi">7</span><span class="p">],</span> <span class="p">[</span><span class="o">.</span><span class="mi">4</span><span class="p">,</span> <span class="o">.</span><span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="o">.</span><span class="mi">6</span><span class="p">,</span> <span class="o">.</span><span class="mi">4</span><span class="p">]]],</span>  <span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">])</span>
<span class="go">0.87702971998</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>classifier_predictions</strong> (<em>numeric values</em>) -- </p></li>
<li><p><strong>rater_labels</strong> (<em>sequence of labels</em><em>, </em><em>which should be numeric values</em>) -- </p></li>
<li><p><strong>verbosity</strong> -- </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Cross Entropy score</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="surveyequivalence.scoring_functions.F1Score">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">surveyequivalence.scoring_functions.</span></code><code class="sig-name descname"><span class="pre">F1Score</span></code><a class="headerlink" href="#surveyequivalence.scoring_functions.F1Score" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#surveyequivalence.scoring_functions.Scorer" title="surveyequivalence.scoring_functions.Scorer"><code class="xref py py-class docutils literal notranslate"><span class="pre">surveyequivalence.scoring_functions.Scorer</span></code></a></p>
<dl class="py method">
<dt id="surveyequivalence.scoring_functions.F1Score.score">
<em class="property"><span class="pre">static</span> </em><code class="sig-name descname"><span class="pre">score</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">classifier_predictions</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#surveyequivalence.combiners.DiscreteDistributionPrediction" title="surveyequivalence.combiners.DiscreteDistributionPrediction"><span class="pre">surveyequivalence.combiners.DiscreteDistributionPrediction</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rater_labels</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbosity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">average</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">'micro'</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">float</span><a class="headerlink" href="#surveyequivalence.scoring_functions.F1Score.score" title="Permalink to this definition">¶</a></dt>
<dd><p>F1 score. This function uses sklearn's F1 function.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">F1Score</span><span class="o">.</span><span class="n">score</span><span class="p">([</span><span class="n">DiscreteDistributionPrediction</span><span class="p">([</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">],</span> <span class="n">prs</span><span class="p">)</span> <span class="k">for</span> <span class="n">prs</span> <span class="ow">in</span> <span class="p">[[</span><span class="o">.</span><span class="mi">3</span><span class="p">,</span> <span class="o">.</span><span class="mi">7</span><span class="p">],</span> <span class="p">[</span><span class="o">.</span><span class="mi">4</span><span class="p">,</span> <span class="o">.</span><span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="o">.</span><span class="mi">6</span><span class="p">,</span> <span class="o">.</span><span class="mi">4</span><span class="p">]]],</span>  <span class="p">[</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">],</span> <span class="s1">&#39;micro&#39;</span><span class="p">)</span>
<span class="go">0.6666666666666666</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">F1Score</span><span class="o">.</span><span class="n">score</span><span class="p">([</span><span class="n">DiscreteDistributionPrediction</span><span class="p">([</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">],</span> <span class="n">prs</span><span class="p">)</span> <span class="k">for</span> <span class="n">prs</span> <span class="ow">in</span> <span class="p">[[</span><span class="o">.</span><span class="mi">3</span><span class="p">,</span> <span class="o">.</span><span class="mi">7</span><span class="p">],</span> <span class="p">[</span><span class="o">.</span><span class="mi">4</span><span class="p">,</span> <span class="o">.</span><span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="o">.</span><span class="mi">6</span><span class="p">,</span> <span class="o">.</span><span class="mi">4</span><span class="p">]]],</span>  <span class="p">[</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">],</span> <span class="s1">&#39;macro&#39;</span><span class="p">)</span>
<span class="go">0.39759036144</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">F1Score</span><span class="o">.</span><span class="n">score</span><span class="p">([</span><span class="n">DiscreteDistributionPrediction</span><span class="p">([</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">],</span> <span class="n">prs</span><span class="p">)</span> <span class="k">for</span> <span class="n">prs</span> <span class="ow">in</span> <span class="p">[[</span><span class="o">.</span><span class="mi">3</span><span class="p">,</span> <span class="o">.</span><span class="mi">7</span><span class="p">],</span> <span class="p">[</span><span class="o">.</span><span class="mi">4</span><span class="p">,</span> <span class="o">.</span><span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="o">.</span><span class="mi">6</span><span class="p">,</span> <span class="o">.</span><span class="mi">4</span><span class="p">]]],</span>  <span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">],</span> <span class="s1">&#39;micro&#39;</span><span class="p">)</span>
<span class="go">0.3333333333333333</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">F1Score</span><span class="o">.</span><span class="n">score</span><span class="p">([</span><span class="n">DiscreteDistributionPrediction</span><span class="p">([</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">],</span> <span class="n">prs</span><span class="p">)</span> <span class="k">for</span> <span class="n">prs</span> <span class="ow">in</span> <span class="p">[[</span><span class="o">.</span><span class="mi">3</span><span class="p">,</span> <span class="o">.</span><span class="mi">7</span><span class="p">],</span> <span class="p">[</span><span class="o">.</span><span class="mi">4</span><span class="p">,</span> <span class="o">.</span><span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="o">.</span><span class="mi">6</span><span class="p">,</span> <span class="o">.</span><span class="mi">4</span><span class="p">]]],</span>  <span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">],</span> <span class="s1">&#39;macro&#39;</span><span class="p">)</span>
<span class="go">0.25</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>classifier_predictions</strong> (<em>numeric values</em>) -- </p></li>
<li><p><strong>rater_labels</strong> (<em>sequence of labels</em><em>, </em><em>which should be numeric values</em>) -- </p></li>
<li><p><strong>verbosity</strong> -- </p></li>
<li><p><strong>average</strong> (<em>macro</em><em> or </em><em>micro averaging</em>) -- </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>F1 Score</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="surveyequivalence.scoring_functions.PrecisionScore">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">surveyequivalence.scoring_functions.</span></code><code class="sig-name descname"><span class="pre">PrecisionScore</span></code><a class="headerlink" href="#surveyequivalence.scoring_functions.PrecisionScore" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#surveyequivalence.scoring_functions.Scorer" title="surveyequivalence.scoring_functions.Scorer"><code class="xref py py-class docutils literal notranslate"><span class="pre">surveyequivalence.scoring_functions.Scorer</span></code></a></p>
<dl class="py method">
<dt id="surveyequivalence.scoring_functions.PrecisionScore.score">
<em class="property"><span class="pre">static</span> </em><code class="sig-name descname"><span class="pre">score</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">classifier_predictions</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#surveyequivalence.combiners.DiscreteDistributionPrediction" title="surveyequivalence.combiners.DiscreteDistributionPrediction"><span class="pre">surveyequivalence.combiners.DiscreteDistributionPrediction</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rater_labels</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbosity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">average</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">'micro'</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">float</span><a class="headerlink" href="#surveyequivalence.scoring_functions.PrecisionScore.score" title="Permalink to this definition">¶</a></dt>
<dd><p>Precision score. This function uses sklearn's precision function.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">PrecisionScore</span><span class="o">.</span><span class="n">score</span><span class="p">([</span><span class="n">DiscreteDistributionPrediction</span><span class="p">([</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">],</span> <span class="n">prs</span><span class="p">)</span> <span class="k">for</span> <span class="n">prs</span> <span class="ow">in</span> <span class="p">[[</span><span class="o">.</span><span class="mi">3</span><span class="p">,</span> <span class="o">.</span><span class="mi">7</span><span class="p">],</span> <span class="p">[</span><span class="o">.</span><span class="mi">4</span><span class="p">,</span> <span class="o">.</span><span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="o">.</span><span class="mi">6</span><span class="p">,</span> <span class="o">.</span><span class="mi">4</span><span class="p">]]],</span>  <span class="p">[</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">],</span> <span class="s1">&#39;micro&#39;</span><span class="p">)</span>
<span class="go">0.6666666666666666</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">PrecisionScore</span><span class="o">.</span><span class="n">score</span><span class="p">([</span><span class="n">DiscreteDistributionPrediction</span><span class="p">([</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">],</span> <span class="n">prs</span><span class="p">)</span> <span class="k">for</span> <span class="n">prs</span> <span class="ow">in</span> <span class="p">[[</span><span class="o">.</span><span class="mi">3</span><span class="p">,</span> <span class="o">.</span><span class="mi">7</span><span class="p">],</span> <span class="p">[</span><span class="o">.</span><span class="mi">4</span><span class="p">,</span> <span class="o">.</span><span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="o">.</span><span class="mi">6</span><span class="p">,</span> <span class="o">.</span><span class="mi">4</span><span class="p">]]],</span>  <span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">],</span> <span class="s1">&#39;micro&#39;</span><span class="p">)</span>
<span class="go">0.3333333333333333</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>classifier_predictions</strong> (<em>numeric values</em>) -- </p></li>
<li><p><strong>rater_labels</strong> (<em>sequence of labels</em><em>, </em><em>which should be numeric values</em>) -- </p></li>
<li><p><strong>verbosity</strong> -- </p></li>
<li><p><strong>average</strong> (<em>macro</em><em> or </em><em>micro averaging</em>) -- </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Precision Score</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="surveyequivalence.scoring_functions.RecallScore">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">surveyequivalence.scoring_functions.</span></code><code class="sig-name descname"><span class="pre">RecallScore</span></code><a class="headerlink" href="#surveyequivalence.scoring_functions.RecallScore" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#surveyequivalence.scoring_functions.Scorer" title="surveyequivalence.scoring_functions.Scorer"><code class="xref py py-class docutils literal notranslate"><span class="pre">surveyequivalence.scoring_functions.Scorer</span></code></a></p>
<dl class="py method">
<dt id="surveyequivalence.scoring_functions.RecallScore.score">
<em class="property"><span class="pre">static</span> </em><code class="sig-name descname"><span class="pre">score</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">classifier_predictions</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#surveyequivalence.combiners.DiscreteDistributionPrediction" title="surveyequivalence.combiners.DiscreteDistributionPrediction"><span class="pre">surveyequivalence.combiners.DiscreteDistributionPrediction</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rater_labels</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbosity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">average</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">'micro'</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">float</span><a class="headerlink" href="#surveyequivalence.scoring_functions.RecallScore.score" title="Permalink to this definition">¶</a></dt>
<dd><p>Recall score. This function uses sklearn's recall function.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">RecallScore</span><span class="o">.</span><span class="n">score</span><span class="p">([</span><span class="n">DiscreteDistributionPrediction</span><span class="p">([</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">],</span> <span class="n">prs</span><span class="p">)</span> <span class="k">for</span> <span class="n">prs</span> <span class="ow">in</span> <span class="p">[[</span><span class="o">.</span><span class="mi">3</span><span class="p">,</span> <span class="o">.</span><span class="mi">7</span><span class="p">],</span> <span class="p">[</span><span class="o">.</span><span class="mi">4</span><span class="p">,</span> <span class="o">.</span><span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="o">.</span><span class="mi">6</span><span class="p">,</span> <span class="o">.</span><span class="mi">4</span><span class="p">]]],</span>  <span class="p">[</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">],</span> <span class="s1">&#39;micro&#39;</span><span class="p">)</span>
<span class="go">0.6666666666666666</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">RecallScore</span><span class="o">.</span><span class="n">score</span><span class="p">([</span><span class="n">DiscreteDistributionPrediction</span><span class="p">([</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">],</span> <span class="n">prs</span><span class="p">)</span> <span class="k">for</span> <span class="n">prs</span> <span class="ow">in</span> <span class="p">[[</span><span class="o">.</span><span class="mi">3</span><span class="p">,</span> <span class="o">.</span><span class="mi">7</span><span class="p">],</span> <span class="p">[</span><span class="o">.</span><span class="mi">4</span><span class="p">,</span> <span class="o">.</span><span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="o">.</span><span class="mi">6</span><span class="p">,</span> <span class="o">.</span><span class="mi">4</span><span class="p">]]],</span>  <span class="p">[</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">],</span> <span class="s1">&#39;macro&#39;</span><span class="p">)</span>
<span class="go">0.5</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">RecallScore</span><span class="o">.</span><span class="n">score</span><span class="p">([</span><span class="n">DiscreteDistributionPrediction</span><span class="p">([</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">],</span> <span class="n">prs</span><span class="p">)</span> <span class="k">for</span> <span class="n">prs</span> <span class="ow">in</span> <span class="p">[[</span><span class="o">.</span><span class="mi">3</span><span class="p">,</span> <span class="o">.</span><span class="mi">7</span><span class="p">],</span> <span class="p">[</span><span class="o">.</span><span class="mi">4</span><span class="p">,</span> <span class="o">.</span><span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="o">.</span><span class="mi">6</span><span class="p">,</span> <span class="o">.</span><span class="mi">4</span><span class="p">]]],</span>  <span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">],</span> <span class="s1">&#39;micro&#39;</span><span class="p">)</span>
<span class="go">0.3333333333333333</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">RecallScore</span><span class="o">.</span><span class="n">score</span><span class="p">([</span><span class="n">DiscreteDistributionPrediction</span><span class="p">([</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">],</span> <span class="n">prs</span><span class="p">)</span> <span class="k">for</span> <span class="n">prs</span> <span class="ow">in</span> <span class="p">[[</span><span class="o">.</span><span class="mi">3</span><span class="p">,</span> <span class="o">.</span><span class="mi">7</span><span class="p">],</span> <span class="p">[</span><span class="o">.</span><span class="mi">4</span><span class="p">,</span> <span class="o">.</span><span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="o">.</span><span class="mi">6</span><span class="p">,</span> <span class="o">.</span><span class="mi">4</span><span class="p">]]],</span>  <span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">],</span> <span class="s1">&#39;macro&#39;</span><span class="p">)</span>
<span class="go">0.25</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>classifier_predictions</strong> (<em>numeric values</em>) -- </p></li>
<li><p><strong>rater_labels</strong> (<em>sequence of labels</em><em>, </em><em>which should be numeric values</em>) -- </p></li>
<li><p><strong>verbosity</strong> -- </p></li>
<li><p><strong>average</strong> (<em>macro</em><em> or </em><em>micro averaging</em>) -- </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Recall Score</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="surveyequivalence.scoring_functions.Scorer">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">surveyequivalence.scoring_functions.</span></code><code class="sig-name descname"><span class="pre">Scorer</span></code><a class="headerlink" href="#surveyequivalence.scoring_functions.Scorer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">abc.ABC</span></code></p>
<p>Scorer that defines a Scorer class as having a score() function. The scorer computes the goodness of a predictor
against the average human rater.</p>
<dl class="py method">
<dt id="surveyequivalence.scoring_functions.Scorer.score">
<em class="property"><span class="pre">abstract</span> <span class="pre">static</span> </em><code class="sig-name descname"><span class="pre">score</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">classifier_predictions</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#surveyequivalence.combiners.DiscreteDistributionPrediction" title="surveyequivalence.combiners.DiscreteDistributionPrediction"><span class="pre">surveyequivalence.combiners.DiscreteDistributionPrediction</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rater_labels</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#surveyequivalence.combiners.DiscreteDistributionPrediction" title="surveyequivalence.combiners.DiscreteDistributionPrediction"><span class="pre">surveyequivalence.combiners.DiscreteDistributionPrediction</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">float</span><a class="headerlink" href="#surveyequivalence.scoring_functions.Scorer.score" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="surveyequivalence.scoring_functions.Scorer.score_classifier">
<code class="sig-name descname"><span class="pre">score_classifier</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">classifier_predictions</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Sequence</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">raters</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Sequence</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">W</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbosity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.scoring_functions.Scorer.score_classifier" title="Permalink to this definition">¶</a></dt>
<dd><p>Driver function that computes the mean score over all predictions</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>classifier_predictions</strong> (<em>Scoring predictions</em>) -- </p></li>
<li><p><strong>raters</strong> (<em>The reference ratings. Score will compare classifier predictions with each rater in turn.</em>) -- </p></li>
<li><p><strong>W</strong> (<em>The item and rating dataset</em>) -- </p></li>
<li><p><strong>verbosity</strong> (<em>verbosity value from 1 to 4 indicating increased verbosity.</em>) -- </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Mean score over all predictions for all raters.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="synthetic-dataset-generation">
<h2>Synthetic Dataset Generation<a class="headerlink" href="#synthetic-dataset-generation" title="Permalink to this headline">¶</a></h2>
<div class="section" id="states">
<h3>States<a class="headerlink" href="#states" title="Permalink to this headline">¶</a></h3>
<dl class="py class">
<dt id="surveyequivalence.synthetic_datasets.DiscreteState">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">surveyequivalence.synthetic_datasets.</span></code><code class="sig-name descname"><span class="pre">DiscreteState</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state_name</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">probabilities</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.synthetic_datasets.DiscreteState" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">surveyequivalence.synthetic_datasets.State</span></code></p>
<p>A discrete distribution over possible labels</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>state_name</strong> -- </p></li>
<li><p><strong>labels</strong> -- A sequence of strings; the allowable labels</p></li>
<li><p><strong>probabilities</strong> -- A sequence of the same length, with values adding to one, giving probabilities for each of the label strings</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="surveyequivalence.synthetic_datasets.DiscreteState.draw_labels">
<code class="sig-name descname"><span class="pre">draw_labels</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.synthetic_datasets.DiscreteState.draw_labels" title="Permalink to this definition">¶</a></dt>
<dd><p>Make n iid draws of discrete labels from the distribution</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>n</strong> -- How many labels to draw from the distribution</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>a single item or a numpy array</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="distributions-over-states">
<h3>Distributions Over States<a class="headerlink" href="#distributions-over-states" title="Permalink to this headline">¶</a></h3>
<dl class="py class">
<dt id="surveyequivalence.synthetic_datasets.DistributionOverStates">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">surveyequivalence.synthetic_datasets.</span></code><code class="sig-name descname"><span class="pre">DistributionOverStates</span></code><a class="headerlink" href="#surveyequivalence.synthetic_datasets.DistributionOverStates" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">abc.ABC</span></code></p>
<p>Abstract base class</p>
</dd></dl>

<dl class="py class">
<dt id="surveyequivalence.synthetic_datasets.DiscreteDistributionOverStates">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">surveyequivalence.synthetic_datasets.</span></code><code class="sig-name descname"><span class="pre">DiscreteDistributionOverStates</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">states</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">surveyequivalence.synthetic_datasets.State</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">probabilities</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.synthetic_datasets.DiscreteDistributionOverStates" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#surveyequivalence.synthetic_datasets.DistributionOverStates" title="surveyequivalence.synthetic_datasets.DistributionOverStates"><code class="xref py py-class docutils literal notranslate"><span class="pre">surveyequivalence.synthetic_datasets.DistributionOverStates</span></code></a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>states</strong> -- a sequence of State objects</p></li>
<li><p><strong>probabilities</strong> -- a same length sequence of floats representing probabilities of the item states</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="surveyequivalence.synthetic_datasets.DiscreteDistributionOverStates.draw_states">
<code class="sig-name descname"><span class="pre">draw_states</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#surveyequivalence.synthetic_datasets.DiscreteState" title="surveyequivalence.synthetic_datasets.DiscreteState"><span class="pre">surveyequivalence.synthetic_datasets.DiscreteState</span></a><span class="p"><span class="pre">]</span></span><a class="headerlink" href="#surveyequivalence.synthetic_datasets.DiscreteDistributionOverStates.draw_states" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>n</strong> -- </p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>a single item or numpy array of State instances, drawn iid from the probability distribution</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="surveyequivalence.synthetic_datasets.FixedStateGenerator">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">surveyequivalence.synthetic_datasets.</span></code><code class="sig-name descname"><span class="pre">FixedStateGenerator</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">states</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">surveyequivalence.synthetic_datasets.State</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">probabilities</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.synthetic_datasets.FixedStateGenerator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#surveyequivalence.synthetic_datasets.DiscreteDistributionOverStates" title="surveyequivalence.synthetic_datasets.DiscreteDistributionOverStates"><code class="xref py py-class docutils literal notranslate"><span class="pre">surveyequivalence.synthetic_datasets.DiscreteDistributionOverStates</span></code></a></p>
<dl class="py method">
<dt id="surveyequivalence.synthetic_datasets.FixedStateGenerator.draw_states">
<code class="sig-name descname"><span class="pre">draw_states</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.synthetic_datasets.FixedStateGenerator.draw_states" title="Permalink to this definition">¶</a></dt>
<dd><p>Draw exactly in proportion to probabilities, rather than each draw random according to the probabilities
:param n: How many items to draw</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>list of State instances</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="mock-classifiers">
<h3>Mock Classifiers<a class="headerlink" href="#mock-classifiers" title="Permalink to this headline">¶</a></h3>
<dl class="py class">
<dt id="surveyequivalence.synthetic_datasets.MockClassifier">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">surveyequivalence.synthetic_datasets.</span></code><code class="sig-name descname"><span class="pre">MockClassifier</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label_predictors</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><a class="reference internal" href="#surveyequivalence.combiners.Prediction" title="surveyequivalence.combiners.Prediction"><span class="pre">surveyequivalence.combiners.Prediction</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.synthetic_datasets.MockClassifier" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>A mock classifier has access to each item's state when generating a prediction,
something that a real classifier would not have access to</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> -- </p></li>
<li><p><strong>label_predictions</strong> -- a dictionary mapping from item state names to Predictions</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="surveyequivalence.synthetic_datasets.MockClassifier.make_predictions">
<code class="sig-name descname"><span class="pre">make_predictions</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">item_states</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">surveyequivalence.synthetic_datasets.State</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#surveyequivalence.combiners.Prediction" title="surveyequivalence.combiners.Prediction"><span class="pre">surveyequivalence.combiners.Prediction</span></a><span class="p"><span class="pre">]</span></span><a class="headerlink" href="#surveyequivalence.synthetic_datasets.MockClassifier.make_predictions" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>item_states</strong> -- a sequence of State objects, representing the states of some items</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>a sequence of Prediction objects, one for each item</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="surveyequivalence.synthetic_datasets.MappedDiscreteMockClassifier">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">surveyequivalence.synthetic_datasets.</span></code><code class="sig-name descname"><span class="pre">MappedDiscreteMockClassifier</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label_predictors</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><a class="reference internal" href="#surveyequivalence.combiners.Prediction" title="surveyequivalence.combiners.Prediction"><span class="pre">surveyequivalence.combiners.Prediction</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prediction_map</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><a class="reference internal" href="#surveyequivalence.combiners.Prediction" title="surveyequivalence.combiners.Prediction"><span class="pre">surveyequivalence.combiners.Prediction</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.synthetic_datasets.MappedDiscreteMockClassifier" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#surveyequivalence.synthetic_datasets.MockClassifier" title="surveyequivalence.synthetic_datasets.MockClassifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">surveyequivalence.synthetic_datasets.MockClassifier</span></code></a></p>
<p>A mock classifier that maps an item state to a Prediction,     draws a discrete label from that,     and then maps that discrete label to another Prediction.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> -- </p></li>
<li><p><strong>label_predictions</strong> -- a dictionary mapping from item state names to Predictions</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="surveyequivalence.synthetic_datasets.MappedDiscreteMockClassifier.make_predictions">
<code class="sig-name descname"><span class="pre">make_predictions</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">item_states</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.synthetic_datasets.MappedDiscreteMockClassifier.make_predictions" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>item_states</strong> -- a sequence of State objects, representing the states of some items</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>a sequence of Prediction objects, one for each item</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="dataset-generators">
<h3>Dataset Generators<a class="headerlink" href="#dataset-generators" title="Permalink to this headline">¶</a></h3>
<dl class="py class">
<dt id="surveyequivalence.synthetic_datasets.SyntheticDatasetGenerator">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">surveyequivalence.synthetic_datasets.</span></code><code class="sig-name descname"><span class="pre">SyntheticDatasetGenerator</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">item_state_generator</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#surveyequivalence.synthetic_datasets.DistributionOverStates" title="surveyequivalence.synthetic_datasets.DistributionOverStates"><span class="pre">surveyequivalence.synthetic_datasets.DistributionOverStates</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_items_per_dataset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_labels_per_item</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mock_classifiers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.synthetic_datasets.SyntheticDatasetGenerator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Generator for a set of items with some raters per item.
Items are defined by States, which are drawn from a DistributionOverStates.
Each State is a distribution over labels.
Each label is an i.i.d. draw from the State</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>item_state_generator</strong> -- </p></li>
<li><p><strong>num_items_per_dataset</strong> -- </p></li>
<li><p><strong>num_labels_per_item</strong> -- How many raters to generate labels for, for each item</p></li>
<li><p><strong>mock_classifiers</strong> -- A list of MockClassifier instances, which generate label predictions based on the item state</p></li>
<li><p><strong>name</strong> -- A text string naming this dataset generator</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="surveyequivalence.synthetic_datasets.SyntheticDatasetGenerator.generate_labels">
<code class="sig-name descname"><span class="pre">generate_labels</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">item_states</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_labels_per_item</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rater_prefix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'e'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.synthetic_datasets.SyntheticDatasetGenerator.generate_labels" title="Permalink to this definition">¶</a></dt>
<dd><p>Normally called with item_states=self.reference_rater_item_states</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>self</strong> -- </p></li>
<li><p><strong>item_states</strong> -- a list of States, one for each item</p></li>
<li><p><strong>num_labels_per_item=None</strong> -- if None, use self.num_labels_per_item</p></li>
<li><p><strong>rater_prefix=&quot;e&quot;</strong> -- Rater columns are named as <cite>f&quot;{rater_prefix}_{i}&quot;</cite> where i is an integer</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>A pandas DataFrame with one row for each item and one column for each rater. Cells are labels.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="surveyequivalence.synthetic_datasets.SyntheticBinaryDatasetGenerator">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">surveyequivalence.synthetic_datasets.</span></code><code class="sig-name descname"><span class="pre">SyntheticBinaryDatasetGenerator</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">item_state_generator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_items_per_dataset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">50</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_labels_per_item</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mock_classifiers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pct_noise</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k_other_raters_per_label</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.synthetic_datasets.SyntheticBinaryDatasetGenerator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#surveyequivalence.synthetic_datasets.SyntheticDatasetGenerator" title="surveyequivalence.synthetic_datasets.SyntheticDatasetGenerator"><code class="xref py py-class docutils literal notranslate"><span class="pre">surveyequivalence.synthetic_datasets.SyntheticDatasetGenerator</span></code></a></p>
<p>Dataset generator for binary labels</p>
<p>Only additional parameters for this subclass are documented here.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pct_noise=0</strong> -- In addition to the reference rater labels, this generator can generator labels from &quot;other&quot; raters.         With probability pct_noise the binary labels will be drawn from a 50-50 coin flip, and otherwise from        the item's State.
If pct_noise==0, the other raters' labels will always be i.i.d draws from the same distribution as the
reference rater labels.</p></li>
<li><p><strong>k_other_raters_per_label=1</strong> -- The number of other raters to generate labels for.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="surveyequivalence.synthetic_datasets.SyntheticBinaryDatasetGenerator.make_histogram">
<code class="sig-name descname"><span class="pre">make_histogram</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ax</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.synthetic_datasets.SyntheticBinaryDatasetGenerator.make_histogram" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>ax</strong> -- A matplotlib Axes instance</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="surveyequivalence.synthetic_datasets.SyntheticBinaryDatasetGenerator.plot_item_state_distribution">
<code class="sig-name descname"><span class="pre">plot_item_state_distribution</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.synthetic_datasets.SyntheticBinaryDatasetGenerator.plot_item_state_distribution" title="Permalink to this definition">¶</a></dt>
<dd><p>called if you are making a standalone graph; for insets, .make_histogram is called directly</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="dataset">
<h3>Dataset<a class="headerlink" href="#dataset" title="Permalink to this headline">¶</a></h3>
<dl class="py class">
<dt id="surveyequivalence.synthetic_datasets.Dataset">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">surveyequivalence.synthetic_datasets.</span></code><code class="sig-name descname"><span class="pre">Dataset</span></code><a class="headerlink" href="#surveyequivalence.synthetic_datasets.Dataset" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>A Dataset</p>
</dd></dl>

<dl class="py class">
<dt id="surveyequivalence.synthetic_datasets.SyntheticDataset">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">surveyequivalence.synthetic_datasets.</span></code><code class="sig-name descname"><span class="pre">SyntheticDataset</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ds_generator</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#surveyequivalence.synthetic_datasets.SyntheticBinaryDatasetGenerator" title="surveyequivalence.synthetic_datasets.SyntheticBinaryDatasetGenerator"><span class="pre">surveyequivalence.synthetic_datasets.SyntheticBinaryDatasetGenerator</span></a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.synthetic_datasets.SyntheticDataset" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#surveyequivalence.synthetic_datasets.Dataset" title="surveyequivalence.synthetic_datasets.Dataset"><code class="xref py py-class docutils literal notranslate"><span class="pre">surveyequivalence.synthetic_datasets.Dataset</span></code></a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ds_generator</strong> -- </p></li>
<li><p><strong>all the attributes</strong> (<em>Sets</em>) -- </p></li>
<li><p><strong>running the SyntheticBinaryDatasetGenerator</strong> (<em>by</em>) -- </p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="surveyequivalence.synthetic_datasets.SyntheticDataset.save">
<code class="sig-name descname"><span class="pre">save</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dirname</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'running_example'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#surveyequivalence.synthetic_datasets.SyntheticDataset.save" title="Permalink to this definition">¶</a></dt>
<dd><p>Save ratings and predictions to csv files</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dirname</strong> -- A subdirectory name in which to store saved results</p></li>
<li><p><strong>include_timestamp_in_dirname</strong> -- Whether to postpend directory name with current timestamp</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="surveyequivalence.synthetic_datasets.make_running_example_dataset">
<code class="sig-prename descclassname"><span class="pre">surveyequivalence.synthetic_datasets.</span></code><code class="sig-name descname"><span class="pre">make_running_example_dataset</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_items_per_dataset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_labels_per_item</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">minimal</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include_hard_classifier</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include_soft_classifier</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> &#x2192; <a class="reference internal" href="#surveyequivalence.synthetic_datasets.SyntheticDataset" title="surveyequivalence.synthetic_datasets.SyntheticDataset"><span class="pre">surveyequivalence.synthetic_datasets.SyntheticDataset</span></a><a class="headerlink" href="#surveyequivalence.synthetic_datasets.make_running_example_dataset" title="Permalink to this definition">¶</a></dt>
<dd><p>This generates the running example dataset used in the original Survey Equivalence paper.</p>
<p>Three states: 70% high = 80/20, 10% med = 50/50; 20% low = 10/90</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_items_per_dataset</strong> -- </p></li>
<li><p><strong>num_labels_per_item</strong> -- </p></li>
<li><p><strong>minimal</strong> -- If minimal, use FixedStateGenerator, which generates labels in exact proportion to probabilities specified         in the state, rather than each label being an iid draw from the State.</p></li>
<li><p><strong>include_hard_classifier</strong> -- Includes a hard classifier which draws labels 90/10 for high state; 50/50 for medium; 05/95 fow low state</p></li>
<li><p><strong>include_soft_classifier</strong> -- Includes a soft classifier which runs the hard_classifier to generate a label and then maps it to a calibrated         prediction (.7681 when the label is positive; .3226 when the label is negative). Also includes an ideal         classifier that always predicts the probability given by the State of the item.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</div>
</div>
</div>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">SurveyEquivalence</a></h1>








<h3>Navigation</h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="getting_started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorials.html">Tutorials</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">API</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#equivalence-module">Equivalence Module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#analysispipeline">AnalysisPipeline</a></li>
<li class="toctree-l3"><a class="reference internal" href="#plot">Plot</a></li>
<li class="toctree-l3"><a class="reference internal" href="#equivalences">Equivalences</a></li>
<li class="toctree-l3"><a class="reference internal" href="#classifierresults">ClassifierResults</a></li>
<li class="toctree-l3"><a class="reference internal" href="#powercurve">PowerCurve</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-surveyequivalence.combiners">Combiners</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-surveyequivalence.scoring_functions">Scoring Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="#synthetic-dataset-generation">Synthetic Dataset Generation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#states">States</a></li>
<li class="toctree-l3"><a class="reference internal" href="#distributions-over-states">Distributions Over States</a></li>
<li class="toctree-l3"><a class="reference internal" href="#mock-classifiers">Mock Classifiers</a></li>
<li class="toctree-l3"><a class="reference internal" href="#dataset-generators">Dataset Generators</a></li>
<li class="toctree-l3"><a class="reference internal" href="#dataset">Dataset</a></li>
</ul>
</li>
</ul>
</li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
      <li>Previous: <a href="tutorials.html" title="previous chapter">Tutorials</a></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2021, Paul Resnick, Yuqing Kong, Grant Schoenebeck, Tim Weninger.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 3.5.0</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="_sources/api.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>